\documentclass[paper=a4paper,fontsize=10pt]{jlreq}
\usepackage{luatexja-fontspec}
\setmainfont{Harano Aji Mincho}
\setsansfont{Harano Aji Gothic}
\setmainjfont{Harano Aji Mincho}
\setsansjfont{Harano Aji Gothic}

\usepackage{amsmath,amssymb}
\usepackage{unicode-math}
\usepackage{url}
\setmathfont{LatinModernMath-Regular}


\begin{document}

\title{Econometrics Note}
\author{
  Sora Maekawa \thanks{一橋大学経済学部 3年, 五年一貫専修コース公共経済プログラム}
}
\maketitle

\section{準備}
\subsection{確率論}
\paragraph{確率空間}
$( \Omega, \mathfrak{P} (\Omega), \mathbb{P} )$ で数学的に定義される. ここで, $ \Omega= \{\omega_1, \dots, \omega_M\} $, $M \in \mathbb{N} $ は標本空間（事象の集まり）,$\mathfrak{P} (\Omega)=\{A:A\subseteq{\Omega} \}$ は$\Omega$ のべき集合（確率を測りたい対象の集まり）で, これに対して $\mathbb{P}:\mathfrak{P}\rightarrow [0,1]$ で確率を与える.\\

\rmfamily\mcfamily\bfseries{Ex. コイントス}\mdseries　結果を確率空間により数学的に記述すると以下のようになる. $M=2$, $\Omega=\{表, 裏\}$, $\mathfrak{P}(\Omega)=\{\phi, \{表\}, \{裏\}, \Omega\}$, $\mathbb{P}(\phi)=0$, $\mathbb{P}(\{表\})=\mathbb{P}(\{裏\})=1/2$, $\mathbb{P}(\Omega)=1$.\\

\paragraph{確率変数}
確率的に値を取る数のことで, 確率空間上の関数として定義される. ある確率変数 $X:\Omega\rightarrow\mathbb{R}$ に対し, 定義域, 値域それぞれの部分集合$A\subseteq\Omega, B\subseteq\mathbb{R}$ を考える. この時, $X(A)=\{X(\omega):\omega\in A\}\subseteq \mathbb{R}$ を $X$ による$A$の像と呼び, $X^{-1}(B)=\{\omega\in \Omega:X(\omega)\in B\}=\{X\in B\}\subseteq \Omega$ を $X$ による$A$の逆像と呼ぶ. \rmfamily\mcfamily\bfseries{NOTATION}\mdseries : $ \{ X \in \{x\} \} \equiv \{ X=x \} $. ここで$x$は$X$の実現値の一つ.\\

\rmfamily\mcfamily\bfseries{Ex. コイントスと賭け}\mdseries　前の例にてコインが表の時$100$ドルを, 裏の時$-50$ドルとなる賭けの損益を$X$とおく. このとき, $X$は確率変数であり, $X(表)=100, X(裏)=-50$（$x\in\{100, -50\}$）. また, $\{X(・) = x = 100\}=\{\omega\in\Omega:X(\omega)=100\}=\{表\}$ （裏でも同様に記せる）から $\mathbb{P}(X=-50)=\mathbb{P}(X=100)=1/2$である. \rmfamily\mcfamily\bfseries{NOTE}\mdseries : 確率変数$X$は事象$\omega$それ自体ではなく, $\omega$ の関数. 今回の場合ならコインの面ではなく, それによる損益.\\

\paragraph{条件付き期待値の諸性質}
$\mathbb{E}(Y)=\mathbb{E}(\mathbb{E}(Y|X))$ は\rmfamily\mcfamily\bfseries{LIE（繰り返し期待値の法則）}\mdseries と呼ばれ, 更に $\mathbb{E}(Y|X)=\mathbb{E}(\mathbb{E}(Y|X, Z)|X)$ （中にある期待値ほど情報集合が小さいことも確認しよう）. 他の変形も確認しよう, 一般に, $X$と$W$を$X=f(W)$の関係性をもつ確率変数とすると, $\mathbb{E}(Y|X)=\mathbb{E}(\mathbb{E}(Y|W)|X)$ である. $X=f(W)=W$のときには, $\mathbb{E}(Y|X)=\mathbb{E}(\mathbb{E}(Y|X)|X)$であることにも注意しよう（回帰の性質を導く際に用いる）. また, $\mathbb{E}(g(X)Y|X)=g(X)\mathbb{E}(Y|X)$ や, 全分散の法則 $Var(Y|X)=\mathbb{E}(Var(Y|X))+Var(\mathbb{E}(Y|X))$ も成立する.\\

\rmfamily\mcfamily\bfseries{Ex. 共分散}\mdseries　二つの確率変数$X,Y$が$P(Y=y|X=x)=P(Y=y)$, つまり独立であるときのことを考える. この場合$\mathbb{E}(Y|X)=\mathbb{E}(Y)=\mu_Y$. つまり, $Y$の条件付き期待値が$X$に依存しないので, 共分散$Cov(X, Y)=\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y)$ は, $\mathbb{E}(XY)=\mathbb{E}(\mathbb{E}(XY|X))=\mathbb{E}(X\mathbb{E}(Y|X))=\mathbb{E}(\mu_Y X)=\mu_Y\mathbb{E}(X)=\mathbb{E}(X)\mathbb{E}(Y)$ より $Cov(X, Y)=0$ となる. \rmfamily\mcfamily\bfseries{NOTE}\mdseries :LIEの派生形を利用した.\\

\paragraph{確率論の諸定理}
イェンセンの不等式(Jensen's Inequality):　$g(X)$が凸関数ならば, $g(\mathbb{E}[X]) \leq (\mathbb{E}[g(X)])$. 特に$g(X)=\left\lvert X \right\rvert $に関しこの公式はExpectation Inequalityと呼ばれる. コーシーシュワルツの不等式(Cauchy-Schwarz Inequality):　$ \left\lvert \mathbb{E}[XY] \right\rvert \leq \sqrt{\mathbb{E}{[X^2]}\mathbb{E}{[Y^2]}}$ チェビシェフの不等式(Chebychev's Inequality):　$Y$を確率変数, $c$を定数とすると, $P(|Y-c|\geq\epsilon)\leq\frac{\mathbb{E}[(Y-c)^2]}{\epsilon^2}$ $\forall\epsilon>0$. チェビシェフの不等式はLLNの証明に利用できることもよく知られている. \\

\subsection{統計的推測}
\paragraph{用語の定義}
$n$個の確率変数 $\{\mathbf{X}_i\}_{i=1}^{n} : \Omega\rightarrow\mathbb{R}^d,  \overset{i.i.d.}{\sim}F$ を考える. このとき, $F$を\rmfamily\mcfamily\bfseries{母集団分布}\mdseries, $\{\mathbf{X}_i\}_{i=1}^{n}$をサイズ$n$の\rmfamily\mcfamily\bfseries{無作為標本}\mdseries とよぶ. $F$の平均, 分散は\rmfamily\mcfamily\bfseries{母平均, 母分散}\mdseries と今後表記する. 実際に我々が得られるデータ$\{\mathbf{x}_i\}_{i=1}^{n}=\{\mathbf{X}_i(\omega)\}_{i=1}^{n}$を\rmfamily\mcfamily\bfseries{実現値}\mdseries, または\rmfamily\mcfamily\bfseries{観測値}\mdseries と呼ぶ. $\{\mathbf{X}_i\}_{i=1}^{n}$ で構成される $\Omega$上のランダムな関数を\rmfamily\mcfamily\bfseries{推定量}\mdseries と呼び, その\rmfamily\mcfamily\bfseries{実現値}\mdseries を\rmfamily\mcfamily\bfseries{推定値}\mdseries という. 推定量 $\hat{\Theta}_n=\hat{\Theta}_n (\mathbf{X}_1, \dots, \mathbf{X}_n)$ が推定したい真のパラメータ $\Theta_n=\Theta_n (F)$ を\rmfamily\mcfamily\bfseries{被推定量}\mdseries という. \rmfamily\mcfamily\bfseries{統計量}\mdseries とは, 標本データから計算される任意の量(Ex. 標本最大値, 中央値)を指し, 必ずしも母集団パラメータを推定するもの（＝推定量）に\rmfamily\mcfamily\bfseries{限らない}\mdseries , ガウス統計量, $\chi^2$統計量, $t$統計量, $F$統計量などが知られている. その中でも\rmfamily\mcfamily\bfseries{検定統計量}\mdseries とは, 仮説検定において, \rmfamily\mcfamily\bfseries{帰無仮説のもとで}\mdseries 分布が特定され, 棄却域の構成に用いられる確率変数のことを指す. 仮説検定で犯しうる誤りは, 帰無仮説を誤って棄却する(タイプⅠエラー)ものと帰無仮説を誤って採択する(タイプⅡエラー)ものの二つである. 仮説検定に先立ち設定される, \rmfamily\mcfamily\bfseries{許容できるタイプⅠエラーの確率}\mdseries $\alpha =P(\text{rejecting } H_0|H_0 \text{ is ture})$こそが\rmfamily\mcfamily\bfseries{有意水準}\mdseries である. 慣習的に選ばれることが多いのは$\alpha=0.05$である. 母集団から同じ方法で100回ランダムに標本を抽出して信頼区間を構成した場合, 約$100(1-\alpha)$回(×確率○割合)信頼区間が真の平均を含むと期待される. 母平均は非確率的であり, 含むか含まないのどちらかのみであるため, 信頼区間については頻度論から議論を行う必要があることに注意せよ. 最後に, $p$値とは\rmfamily\mcfamily\bfseries{『帰無仮説の下で, 実際の実現値と同等かそれ以上に, その帰無仮説に不利な実現値を検定統計量が出す確率』}\mdseries を指す. \\

\rmfamily\mcfamily\bfseries{Ex. 標本平均}\mdseries　$F:\mathbb{R}\rightarrow[0, 1], X, X_1, \dots, X_n \overset{i.i.d.}{\sim}F$ とする. $\mu=\mathbb{E} [X]$, $\sigma^2 = Var(X)$ とし, これを推定するため（被推定量としたとき）の\rmfamily\mcfamily\bfseries{推定量}\mdseries（確率変数, 推定値ではない）を $\hat{\mu}=\hat{\mu}(X_1, \dots, X_n)=\frac{1}{n}\sum_{i = 1}^{n}X_i$ として, これを標本平均$\bar{X_n}$ と定義する. この実現値 $\hat{\mu}=\hat{\mu}(x_1, \dots, x_n)=\frac{1}{n}\sum_{i = 1}^{n}x_i$ が推定値で, これは非確率変数. また, $\mathbb{E}[\hat{\mu}]=\mu$で不偏推定量である. なお, 標本平均の分散は$Var(\bar{X}_n)=\frac{\sigma^2}{n}$であり, この平方根は標準誤差(Standard Error, SE)という. 標本平均のみならず, 他推定量の分散の平方根についても標準誤差と呼ぶ.\\

\rmfamily\mcfamily\bfseries{Ex. $p$値の計算}\mdseries　ソムリエはワインの赤白をその鋭い味覚で感じ取れると言われている. 対して我々はソムリエは違いなど一切分かっていないと疑いの目を向ける. そこで, 彼/彼女に目隠しをつけ, 赤と白の二択でワインを10回区別してもらった. 実際に10回のうち9回は二択を当てることが出来たときの, 帰無仮説『彼/彼女はあてずっぽうで色を言っているだけ』の下での $p$ 値は？\\\rmfamily\mcfamily\bfseries{解答}\mdseries : "帰無仮説の下での分布"は二項分布である. 実現値は9回成功ゆえ, これがあてずっぽうで実現する確率は $10 C 1 \times (1/2)^{10}$. では, "実際と同等かそれ以上に帰無仮説に不利な実現値をだす確率" とは何だろうか? まず, 帰無仮説に不利な実現値はソムリエの成功回数が多い結果のことを指す. つまり今回求めたい確率(= $p$ 値)は9回以上 (＝実際の実現値以上に) 成功する確率. つまり:
\begin{equation*}
  p値 = 10 C 0 \times (1/2)^{10} + 10 C 1 \times (1/2)^{10} = 11/1024
\end{equation*}

\rmfamily\mcfamily\bfseries{Ex. 標本平均の信頼区間}\mdseries　帰無仮説の仮定下では, $P(-c\leq t_\mu\leq c)=1-\alpha$であり, 左辺を変形すると, $P(-c\leq t_\mu\leq c)=P(-c\leq \sqrt{n} \frac{\bar{X_n}-\mu_{X,0}}{\sigma_X} \leq c)=P(\bar{X_n} - c\frac{\sigma_X}{\sqrt{n}} \leq \mu_{X,0} \leq \bar{X_n} + c\frac{\sigma_X}{\sqrt{n}})$であるから, $[\bar{X_n} - c\frac{\sigma_X}{\sqrt{n}}, \bar{X_n} + c\frac{\sigma_X}{\sqrt{n}}]$が$100(1-\alpha)$パーセント信頼区間である. ここで臨界値である$c$や分散推定量である$\frac{\sigma_X}{\sqrt{n}}$は推定の(漸近)分布と状況によって変わることに注意せよ. 標本が十分に大きいときの標本平均について95パーセント信頼区間を構成するならば, $c \approx 1.96$である.\\

\rmfamily\mcfamily\bfseries{Ex. t統計量を用いた両側検定}\mdseries　$X_1, \dots, X_n \overset{i.i.d.}{\sim}\mathcal{N}(\mu_X, \sigma_X^2) $ である. 先ず, $\sigma_X^2$が既知として, $H_0=\mu_{X,0}, \alpha=0.05$の両側検定を考える. ここで, \rmfamily\mcfamily\bfseries{実際に帰無仮説が正しければ}\mdseries , t検定統計量は$T=\sqrt{n} \frac{\bar{X_n}-\mu_{X,0}}{\sigma_X} \sim \mathcal{N}(0, 1)$で標準正規分布に従う. 次に, $\sigma_X^2$も未知として同様の両側検定を考える. ここで, t統計量は$T=\sqrt{n} \frac{\bar{X_n}-\mu_{X,0}}{s_X} = \frac{\sqrt{n} \frac{\bar{X_n}-\mu_{X,0}}{\sigma_X}}{\sqrt{\frac{(n-1)s_X^2 / \sigma_X^2}{n-1}}} \sim t(n-1)$で, 自由度$n-1$のt分布に従う.\\

\paragraph{漸近理論}
確率変数$X$の母集団分布が分かっていないこともしばしばである. その場合, 我々が標本平均などの推定量を構成する意味とは? ここで重要になるのが標本数$n$を無限大に大きくした際の統計量の近似的な性質を探る漸近理論, とくに大標本理論である. $\lim_{n \to \infty} P(\left\lvert z_n - c \right\rvert \geq \epsilon) = 0　\forall \epsilon>0$なら, 数列$\{z_n\}$は$c$に\rmfamily\mcfamily\bfseries{確率収束}\mdseries するという. $z_n \overset{p}{\to} c$かつ $y_n \overset{p}{\to} d$ならば, $z_n + y_n \overset{p}{\to} c+d$ かつ$z_n y_n \overset{p}{\to} c d$. $\{S_n\}$は確率変数列で, $F_n$はこのcdfとして, $F_n$が全ての$F$($S$のcdf)上の連続な点で$F$へ収束するなら, $\{S_n\}$は$S$に\rmfamily\mcfamily\bfseries{分布収束}\mdseries するという, この時の$F$が$S_n$の\rmfamily\mcfamily\bfseries{漸近分布}\mdseries である. 大数の法則(LLN)は確率収束を, 中心極限定理(CLT)は分布収束を用いて定義され, どちらも漸近理論の枠組みでの結果である.\\

\paragraph{漸近理論の諸定理}
スラツキーの定理(Slutsky's Theorem):　$z_n \overset{p}{\to} c$かつ $S_n \overset{d}{\to} S$ならば, $z_n + S_n \overset{d}{\to} c+S$, $z_n S_n \overset{d}{\to} c S$, かつ $S_n / z_n \overset{d}{\to} S / c \text{ if }c\neq0$. 連続写像定理(Continuous Mapping Theorem):　$g$が連続関数のとき, $z_n \overset{p}{\to} c$ならば, $g(z_n) \overset{p}{\to} g(c)$, $S_n \overset{d}{\to} S$ならば, $g(S_n) \overset{d}{\to} g(S)$. 大数の法則(Law of Large Numbers, LLN):　$X_1,\dots, X_n \overset{i.i.d}{\to} F(\mu_X, \sigma^2<\infty)$ ならば, $\bar{X}=\frac{1}{n}\sum_{i = 1}^{n} X_i \overset{p}{\to} \mu_X $. 中心極限定理(Central Limit Theorem, CLT):　$X_1,\dots, X_n \overset{i.i.d}{\to} F(\mu_X, \sigma_X^2<\infty)$ ならば, $\sqrt{n} \frac{\bar{X_n}-\mu_{X}}{\sigma_X} \overset{d}{\to} \mathcal{N}(0, 1)$ である. CLTについては, 標本平均の標準化が行われており, それ故に標本平均の分散$\frac{\sigma^2}{n}$が用いられてこの形になっていることに注意せよ. \\

\rmfamily\mcfamily\bfseries{Ex. 標本分散・共分散}\mdseries　$F:\mathbb{R}\rightarrow[0, 1]　X, X_1, \dots, X_n \overset{i.i.d.}{\sim}F$. 母集団平均$\mu=\mathbb{E} [X]$, 母集団分散$Var(X)=\sigma^2$とし,\rmfamily\mcfamily\bfseries{推定量}\mdseries を $ s^2 = s^2(X_1, \dots, X_n)=\frac{1}{n-1}\sum_{i = 1}^{n}(X_i-\hat{\mu})^2$ として, これを標本分散$s^2$と定義. この実現値 $ s^2 = s^2(x_1, \dots, x_n)=\frac{1}{n-1}\sum_{i = 1}^{n}(x_i-\hat{\mu})^2$ が推定値である. $\mathbb{E}[s^2]=\sigma^2$で不偏推定量である. また, LLNと連続写像定理より$s^2 \overset{p}{\to} \sigma^2$で一致推定量であることも分かる(証明は他資料参照). 標本平均の標準誤差の推定量は, $SE(\bar{X}_n)=\frac{\sigma}{\sqrt{n}} \approx \frac{s}{\sqrt{n}}$と標本分散を利用している. 標本共分散も同様に, (二つの確率変数$(X,Y)$について)$\frac{1}{n-1}\sum_{i = 1}^{n}(X_i-\hat{\mu_X})(Y_i-\hat{\mu_Y})$と構成すれば$Cov(X,Y)$の不偏かつ一致推定量となる事が知られている. \\

\rmfamily\mcfamily\bfseries{Ex. OLSEと標本対応}\mdseries　通常の単回帰モデルに従い生成された$n$組のi.i.d標本$(X_i, Y_i)_{i=1}^{n}$ を用いてOLS推定を行うと, 傾きの推定量$\hat{\beta_1}=\frac{Cov(X,Y)}{Var(X)}$を得られる(後述). この\rmfamily\mcfamily\bfseries{標本対応}\mdseries は$b_1=\frac{s_{X,Y}}{s^{2}_{X}}$だが, この$\beta_1$から$b_1$への標本対応に正統性はあるのだろうか? $X$の母集団分散$Var(X)=\sigma^2$, 母集団共分散$Cov(X,Y)=\sigma_{X,Y}$ に対する不偏・一致推定量として標本分散$s^2_X$, 標本共分散$s_{X,Y}$がある. ここで, 確率収束の性質と連続写像定理より, $\frac{s_{X,Y}}{s^{2}_{X}} \overset{p}{\to} \frac{\sigma_{X,Y}}{\sigma^2}$. 不偏性は$X$条件付期待値を取ったのちLIEを利用すれば確認できる. 以上の議論はOLSEに限らず一般の推定量にも適応でき, 標本対応の正統性を不偏性と一致性の観点から確認できた.\\

\rmfamily\mcfamily\bfseries{Ex. t統計量を用いた両側検定(Cont.)}\mdseries　$X_1, \dots, X_n \overset{i.i.d.}{\sim}$, $\mathbb{E}[X_i^4]<\infty$だが分布が不明な場合の$t$統計量を考える. $T=\sqrt{n} \frac{\bar{X_n}-\mu_{X,0}}{s_X}$を先述のように分解すると, (分母)は$1$に確率収束し, (分子)は$\mathcal{N}(0,1)$に分布収束する(∵CLT). Slutsky's Theoremより, $T=\sqrt{n} \frac{\bar{X_n}-\mu_{X,0}}{s_X} \overset{d}{\to} \mathcal{N}(0, 1)$, つまり\rmfamily\mcfamily\bfseries{t統計量の漸近分布は標準正規分布}\mdseries . 標本サイズが大きい限り標準正規分布で良く近似できるのだ.\\

\subsection{行列}
\rmfamily\mcfamily\bfseries{NOTATION}\mdseries : 行列 $\mathbf{A}$ の転置行列を $\mathbf{A}^{T}$と, $k$次単位行列を$\mathbf{I}_k$と書く. $n$次対称行列 $\mathbf{A}$, $n$次ベクトル$\mathbf{x}$を考えたとき, $\mathbf{x}^T\mathbf{A}\mathbf{x}$を$\mathbf{x}$の\rmfamily\mcfamily\bfseries{2次形式（quadratic form）}\mdseries とよぶ. 全ての$\mathbf{x} \neq  \mathbf{0}$について$\mathbf{x}^T\mathbf{A}\mathbf{x}>0$ ($\mathbf{x}^T\mathbf{A}\mathbf{x}\geq 0$) なら, $\mathbf{A}$は \rmfamily\mcfamily\bfseries{正値定符号行列（非負値定）（positive (semi)definite）}\mdseries と呼び,  $\mathbf{x}^T\mathbf{A}\mathbf{x}<0$ ($\mathbf{x}^T\mathbf{A}\mathbf{x}\leq0$) なら, \rmfamily\mcfamily\bfseries{負値定符号行列（非正値定）（negative (semi)definite）}\mdseries と呼ぶ. \\

\paragraph{階数に関する諸性質}
正則行列$\mathbf{A}$には, $\mathbf{A}\mathbf{c}=\mathbf{0}$の解が $\mathbf{c}=\mathbf{0}$ しか存在せず, また逆行列$\mathbf{A}^{-1}$が存在する. どの$\mathbf{A}$にも, $rank(\mathbf{A})=rank(\mathbf{A}\mathbf{A}^T)=rank(\mathbf{A}^T\mathbf{A})$が成立する. $\mathbf{x}^T\mathbf{A}\mathbf{x}\lessgtr0$ならば$\mathbf{A}$は正則.\\

\paragraph{多変量解析と行列}
$n$次元確率ベクトル$\mathbf{X}^T=(X_1,\dots,X_n)$を考える. この確率ベクトルの期待値は期待値のベクトルであり, 以下のように表せる.
\begin{equation*}
  \mathbf{E[X]} = \begin{pmatrix} \mathbf{\mathbb{E}}[X_1] \\ \vdots \\ \mathbf{\mathbb{E}}[X_n] \end{pmatrix} = \begin{pmatrix} \mu_1 \\ \vdots \\ \mu_n \end{pmatrix} = \mu
\end{equation*}
共分散行列は$\Sigma=\mathbf{Var(X)}=\mathbf{E}((\mathbf{X}-\mu)(\mathbf{X}-\mu)^T)$で与えられる. $Cov(X_i, X_j)=Cov(X_j, X_i)$から, 共分散行列は対称行列であり, また, $\Sigma=\mathbf{E(XX^T)}-{\mu\mu^T}$ である. 次に, 平均ベクトル$\mu$, 共分散行列$\Sigma$, そして定数ベクトル$\mathbf{a}^T=(a_1,\dots,a_n)$を持つ$n$次元確率ベクトル$\mathbf{X}^T=(X_1,\dots,X_n)$を考える. $z=\mathbf{a^T X}=a_1X_1+\dots+a_nX_n$ は確率変数（スカラー）で,  $z$の平均は$\mathbb{E}(z)=a_1\mathbb{E}(X_1)+\dots+a_n\mathbb{E}(X_n)=\mathbf{a^T E(X)}=\mathbf{a^T}\mu$で与えられる. 分散は, $Var(z)=Var(\mathbf{a^T X})=\mathbb{E}((\mathbf{a^T X-a^T} \mu)(\mathbf{a^T X-a^T} \mu)^T)=\mathbb{E}(\mathbf{a}^T (\mathbf{X}-\mu)(\mathbf{X}-\mu)^T \mathbf{a})=\mathbf{a^T}\mathbf{E}({(\mathbf{X}-\mu)(\mathbf{X}-\mu)^T })\mathbf{a}=\mathbf{a^T}\mathbf{Var(X)}\mathbf{a}=\mathbf{a^T} \Sigma \mathbf{a}$（$\Sigma$の2次形式）となる. $Var(z)\geq 0$ゆえ, この2次形式は非負値定符号行列. 更に, 線形結合の集合を考えてみよう. 平均ベクトル$\mu$, 共分散行列$\Sigma$を持つ$n$次元確率ベクトル$\mathbf{X}^T=(X_1,\dots,X_n)$と$n\times K$定数行列$\mathbf{A}$を考える. $\mathbf{z}=\mathbf{A^T X}$ は以下の確率ベクトル（×スカラー）である.
\begin{equation*}
  \mathbf{z}=\mathbf{A^T X} = \begin{pmatrix} a_{1, 1}X_1+\dots+a_{n, 1}X_n \\ \vdots \\ a_{1, K}X_1+\dots+a_{n, K}X_n \end{pmatrix}
\end{equation*}
先ほどと同様に, $z$の平均は$\mathbf{E(z)}=\mathbf{A}^T\mu$で, 分散は$\mathbf{Var(z)}=\mathbf{A}^T \Sigma \mathbf{A}$で与えられる. ベクトル, 行列での微分も可能である. $\frac{\partial g(\mathbf{x})}{\partial \mathbf{x}}$は, $n\times 1$ベクトルで各$x_i$成分での偏微分導関数が対応する. 特に, $n$次ベクトル$\mathbf{a}$と$n$次正方行列$A$について, $\frac{\partial}{\partial \mathbf{x}}\mathbf{a^T x}=\mathbf{a}$, $\frac{\partial}{\partial \mathbf{x^T}}\mathbf{A x}=\mathbf{A^T}$, $\frac{\partial}{\partial \mathbf{x}}\mathbf{x^T A x}=\mathbf{(A+A^T)x}$. 最後に行列の表記を用いた多変数でのCLTを見ておこう. Multivariate Central Limit Theorem (CLT, Lindeberg-Levy):　$\{\mathbf{z}_i\}$はi.i.d, 平均$\mathbf{E}[\mathbf{z}_i]=\mu$で, 共分散行列$\mathbf{Var}(\mathbf{z}_i)=\Sigma$は正値定符号行列かつ有限とする. このとき, $\sqrt{n}(\bar{\mathbf{z}}_n-\mu) \overset{d}{\to}\mathcal{N}(\mathbf{0},\Sigma)$.\\

\section{回帰分析の基礎}
\subsection{回帰分析の必要性}
前提として, 我々の関心は, ある施策によりもたらされた帰結＝\rmfamily\mcfamily\bfseries{因果効果の推定}\mdseries と, 現状のデータを用いた\rmfamily\mcfamily\bfseries{将来の予測}\mdseries の2つにある（予測のみが目標ならば, 因果効果を特定する必要はない）. 理想的な因果推論のための実験として, \rmfamily\mcfamily\bfseries{Randamized Controlled Trial（RCT）}\mdseries がある.\\

\paragraph{ベンチマーク:RCT}
我々が関心を持つ対象が, $X$が一単位変化したときの$Y$への\rmfamily\mcfamily\bfseries{因果効果}\mdseries だとする. RCTでは, $X=1$の処置群と$X=0$の処置群を\rmfamily\mcfamily\bfseries{ランダム}\mdseries に振り分け, グループ間での差異はその処置によるものだけである状況を作り出す. この場合, 処置による\rmfamily\mcfamily\bfseries{因果効果}\mdseries は$\mathbb{E}[Y|X=1]-\mathbb{E}[Y|X=0]$で与えられる. しかし, 我々が入手可能なデータには, 実験データと観測データがあり, 特に観測データにおける処置はランダムに割り当てられているとは限らず, 処置の因果効果を関連要素から切り離して見出すことは困難になる（後述）. ここからはランダムな割り当てが保証されない場合の予測と因果推論についての考察を進める. \\

\paragraph{因果推論と条件付き期待値}
適切な(疑似相関の問題等を考慮した)変数選択の下でコントロールを行い(\rightarrow コントロール変数), \rmfamily\mcfamily\bfseries{ceteris paribus・ほかの条件全て一定}\mdseries の状況を（仮想的に）作り出し, \rmfamily\mcfamily\bfseries{比較静学}\mdseries への導入を行うのが, 特に因果推論の文脈における計量経済学のツールの役割といえる. 平均, または期待される反応に焦点を当てるなら, 比較静学は,$\mathbb{E}(Y|W, \mathbf{C})$, つまり条件付き期待値の推定を必要とする. ここで, ベクトル $\mathbf{C}$ は, $Y$ の期待値に対する $W$ の効果を調査するとき, 明示的に\rmfamily\mcfamily\bfseries{固定したいコントロール変数の集合}\mdseries を示す. $\mathbf{C}$ が上手くコントロールされていれば, $W$が連続のとき, \rmfamily\mcfamily\bfseries{部分効果}\mdseries $\frac{\partial \mathbb{E}(Y|W, \mathbf{C})}{\partial W}$ が直接的に因果効果といえよう. しかし$\mathbf{C}$は観測不可能なことや, 効果を測るための適切な尺度がないこともしばしばである. このような理由から欠落変数バイアスが生じ, 内生性が存在したり(\rightarrow IV法)しうる. 他にも, そもそも因果関係を逆に取り違えたり, 因果関係が実際には見せかけだった, という問題が因果推論にはついて回ることに注意せよ.\\

\rmfamily\mcfamily\bfseries{Ex. 教育の賃金への因果効果}\mdseries　
賃金への影響を与える要因が, 教育年数, 就業年数, そして能力のみであると考えよう. このとき求めるべき部分効果は, $\frac{\partial \mathbb{E}(wage|edu, exper, abil)}{\partial edu}$ で, コントロール変数ベクトル$\mathbf{C}=(exper, abil)$だが能力は\rmfamily\mcfamily\bfseries{観測不可能}\mdseries . \\

\paragraph{予測と条件付き期待値}
一方で, 多くの応用計量経済学での目標は, 説明変数ベクトル $\mathbf{X}$ で条件付けた内生変数 $Y$ の期待値$\mathbb{E}(Y|\mathbf{X})$の\rmfamily\mcfamily\bfseries{推定, 予測, 仮説検定（×因果推論）}\mdseries にある. $Y$の期待値が発散しなければ, $\mathbb{E}(Y|\mathbf{X})=\mu(\mathbf{X})$を満たすような関数$\mu=\mu(\mathbf{X})$が存在して, これが$Y$の$\mathbf{X}$による平均変化をしめす. 経済学では, 条件付き期待値は通常, 有限個のパラメータに依存するように設定される(=\rmfamily\mcfamily\bfseries{パラメトリックモデル}\mdseries ), $\mu$の自由度が下がることに留意せよ.\\

\rmfamily\mcfamily\bfseries{Ex. $K=2$説明変数モデル}\mdseries　
\begin{align}
  \label{eq1}
  \mathbb{E}(Y|\mathbf{X})&=\beta_1+\beta_2X_{2}+\beta_3X_{3}\\
  \label{eq2}
  \mathbb{E}(Y|\mathbf{X})&=\beta_1+\beta_2X_{2}+\beta_3X_{3}+\beta_4X_{3}^{2}\\
  \label{eq3}
  \mathbb{E}(Y|\mathbf{X})&=\beta_1+\beta_2X_{2}+\beta_3X_{3}+\beta_4X_{2}X_{3}\\
  \label{eq4}
  \mathbb{E}(Y|\mathbf{X})&=\exp[\beta_1+\beta_2\log X_{2}+\beta_3X_{3}], y ≥ 0, x_{2} > 0
\end{align}
上三つは\rmfamily\mcfamily\bfseries{パラメータに対して線形}\mdseries , 最後の一つは非線形（∵$\exists\exp$）. 違いは部分効果と弾力性を考慮することで明らかになる（後述）.\\

$\mu$を微分可能な変数としてみなせば, $\Delta\mathbb{E}(Y|\mathbf{X})\approx \frac{\partial \mu(\mathbf{X})}{\partial X_i}\cdot \Delta X_i$ の関係が成立する. 実際に$X$が連続の時の部分効果は前回と同様$\frac{\partial \mathbb{E}(Y|\mathbf{X})}{\partial X_i}$ で, 離散の場合には差分で推定される. 弾力性は$\frac{\partial \log \mathbb{E}(Y|\mathbf{X})}{\partial \log X_i}$.\\

\rmfamily\mcfamily\bfseries{Ex. $K=2$説明変数モデル（Cont.）}\mdseries　変数は連続として考える. それぞれで部分効果を求めると, (\ref{eq1})式では, $(\beta_2, \beta_3)$, (\ref{eq2})式では, $(\beta_2, \beta_2+2\beta_3x_3)$, (\ref{eq3})式では, $(\beta_2, \beta_2+2\beta_3x_3)$, (\ref{eq4})式は複雑に. 関数形で部分効果に他説明変数が介在する状況を表現できると分かる. 一方で,  (\ref{eq4})式の$X_2$に対する弾力性は$\beta_2$で一定. 弾力性推定における両辺$\log$の変換の有効性, $\exp^{-1}(\cdot)=\log(\cdot)$による結果.\\

\subsection{回帰モデルとは}
回帰とは,  \rmfamily\mcfamily\bfseries{被説明変数を説明変数ベクトルによって予測}\mdseries することである. 条件付き期待値$\mathbb{E}[Y|X_{2}]$は\rmfamily\mcfamily\bfseries{$Y$の$X_{2}$への回帰}\mdseries と呼ばれ, 回帰モデルは以下のように表現できる. 
\begin{equation*}
  Y = \mathbb{E}[Y|X_{2}]+(Y-\mathbb{E}[Y|X_{2}])=\mathbb{E}[Y|X_{2}]+\epsilon
\end{equation*}
ここで導入した\rmfamily\mcfamily\bfseries{誤差項（error term）}\mdseries $\epsilon=Y-\mathbb{E}[Y|X_{2}]$は, 両辺に$X_{2}$での条件付き期待値をつけることで, $\mathbb{E}[\epsilon|X_{2}]=\mathbb{E}[Y|X_{2}]-\mathbb{E}[\mathbb{E}[Y|X_{2}]|X_{2}]=0$(∵LIEの変形). ゆえに, $\mathbb{E}[\epsilon|X_{2}]=0$の性質を満たすことが分かる. 更にLIEとその変形より, $\mathbb{E}[\epsilon]=0$, $\mathbb{E}[X_{2}\epsilon]=0$, $\mathbb{E}[h(X_{2})\epsilon]=0$を得る.\\

\paragraph{最小二乗法}
条件付き期待値の, $Y$の予測としての望ましさを確認したい. ここで用いるのは\rmfamily\mcfamily\bfseries{最小二乗法（OLS）}\mdseries である. 確率変数$X$の関数である, $Y$の推定量を$g(X)$とおく. このとき\rmfamily\mcfamily\bfseries{推定誤差}\mdseries は$e=Y-g(X)$で与えられ, 以下の平均二乗誤差（MSE）を最小化するような推定量を考える.
\begin{equation*}
  Loss=\mathbb{E}[(Y-g(X_2))^{2}]
\end{equation*}
これを最小化するのは, $g(X_2)=\mathbb{E}[Y|X_{2}]$であり, 最適な推定量が条件付き期待値と合致することが分かる. 尚, このときの予測誤差$e$は, $e=Y-g(X)=Y-\mathbb{E}[Y|X_{2}]$であることから, 誤差項$\epsilon$と一致することも分かる. ノンパラメトリック回帰は, それぞれの条件付期待値が被説明変数の推定量となる. しかし, この回帰について我々は, データ全体での傾向読み取りが困難であるなどの課題点を学んだ(Rによる実証分析 4章参照).\\

\subsection{単回帰モデルの導入}
先述の回帰モデルにおける条件付き期待値の特定化を図る. 線形単回帰モデルでは, 実際に条件付き期待値が$\mathbb{E}[Y|X_{2}]=\beta_1+\beta_2X_{2}$（＝標本が線形関係に従い生成される）と仮定する. \\

\paragraph{$\beta$の推定}
ここで, 無作為標本 $(X_{1,2}, Y_1), \dots, (X_{n,2}, Y_n)$ が得られたとして, 以下を考える.
\begin{equation*}
  Y_i = \beta_1+\beta_2X_{i,2}+\epsilon_i　i=1,\dots, n
\end{equation*}
ここで, $Y_i$は従属変数, 内生変数, $X_{i,2}$は独立変数, 外生変数, 説明変数などとよばれ, $\epsilon_i$はランダムで観測不可能な\rmfamily\mcfamily\bfseries{誤差項（error term）}\mdseries である. この場合にデータの予測を行いたければ, $(\beta_1, \beta_2)$ （未知）を推定すればよい. では考えうる推定方法は?　\rmfamily\mcfamily\bfseries{NOTE}\mdseries : 単回帰モデルの仮定下では, 誤差項は説明変数の変化を経由しない従属変数変動の要因を全て内包している.\\

\paragraph{単回帰モデルにおける最小二乗法}
一般の回帰モデルと同様に, 先述した最小二乗法を単回帰モデルに適応すれば良い. 上の議論より, $g(X_2)=\mathbb{E}[Y|X_{2}]$である. $\mathbb{E}[Y|X_{2}]=\beta_1+\beta_2X_{2}$, $Y_i = \beta_1+\beta_2X_{i,2}+\epsilon_i　i=1,\dots, n$の場合, 関数形を決定するパラメータとして選択できるのは $(\beta_1, \beta_2)$の2つ. $(\beta_1, \beta_2)$ のOLS推定量 $(\hat{\beta}_1, \hat{\beta}_2)$は, 以下のMSEのminimizerである.
\begin{equation*}
  Loss=\mathbb{E}[e^{2}]=\mathbb{E}[(Y-g(X_2))^{2}]=\mathbb{E}[(Y-\beta_1-\beta_2X_{2})^{2}]
\end{equation*}
FOCで得た正規方程式を用い, OLS推定量 $(\hat{\beta}_1, \hat{\beta}_2)=(\mathbb{E}(Y)-\hat{\beta}_2\mathbb{E}(X_2), \frac{Cov(X_2,Y)}{Var(X_2)})$を得る.\\

\paragraph{$\beta$の推定値}
今, $(X_{1,2}, Y_1), \dots, (X_{n,2}, Y_n)$ と$n$個の無作為標本が与えられ, その\rmfamily\mcfamily\bfseries{実現値}\mdseries $(x_{1,2}, y_1), \dots, (x_{n,2}, y_n)$が判明している下で, MSEを\rmfamily\mcfamily\bfseries{標本平均に置き換え}\mdseries , 以下の二乗誤差の標本平均（$\approx$標本二乗残差（後述））のminimizerとしてOLS推定値（×推定量）$(b_1, b_2)$を決定したい.
\begin{equation*}
  \bar{Loss}=\frac{1}{n}S(b_{1,0}, b_{2, 0})=\frac{1}{n}\sum_{i = 1}^{n} e_{i, 0}^{2}=\frac{1}{n}\sum_{i = 1}^{n} (Y_i-b_{1, 0}-b_{2, 0}X_{i, 2})^{2}
\end{equation*}
この結果, OLS推定量 $(b_1, b_2)=(\bar{Y}-b_2\bar{X}_2, \frac{s_{X_2,Y}}{s^{2}_{X_2}})$ を得る. さらに実データに置き換えれば, $(b_1, b_2)=(\bar{y}-b_2\bar{x}_2, \frac{s_{x_2,y}}{s^{2}_{x_2}})$のOLS推定値が得られる.\\

\paragraph{$y_i$の予測値}
次に, 無作為標本の実現値が与えられ, OLS推定値を用いて導かれる内生変数の予測値に関連する性質を考える. 予測値$\hat{y}_i=b_1+b_2x_{i, 2}$, 残差$e=y_i-\hat{y}_i$とする. このとき, $\bar{e}=0$, $s_{e, x_2}=0$, $\bar{\hat{y}}=\hat{y}$. $e$は$\epsilon$の実現値と見なせるため, $\mathbb{E}[\epsilon]=0$, $\mathbb{E}[X_{2}\epsilon]=0$, $\mathbb{E}[h(X_{2})\epsilon]=0$ に対応した結果であることも分かる. 残差の定義が, 決定係数の定義の解釈に有用であることも留意.\\

\paragraph{標本外の$y_i$の予測}
ここからは, 同様の線形単回帰モデルにおいて, $n$組の無作為標本の実現値が与えられ, ここから構成されたOLS推定値$(b_1, b_2)$を用いた, \rmfamily\mcfamily\bfseries{標本外}\mdseries の内生変数の予測を目標として議論を進める. $\{X_i\}_{i=1}^{n}=\{x_i\}_{i=1}^{n}$ で実現値が与えられており, 単回帰モデルに従って$\{Y_i\}_{i=1}^{n}=\{\beta_1+\beta_2x_{2,i}+\epsilon_i\}_{i=1}^{n}$が生成されるものの, 実現値は未だ与えられていない（∵$\exists\epsilon_i$）場合を考える. この時の$\beta$の推定量（×推定値）は$(b_1, b_2)=(\bar{Y}-b_2\bar{x}_2, \frac{s_{x_2,Y}}{s^{2}_{x_2}})$となり, $\epsilon$の関数なので確率関数として表せて, この期待値をとればOLS推定量の不偏性を示すことが出来る. 更に, 同一母集団同時分布に従う, 標本外の確率変数$(X_{i,2}^{OOS}, Y_i^{OOS})$を考える. 我々のここでの目標は$X_{i,2}^{OOS}=x_i^{OOS}$として実現値を与えられたときの$Y_i^{OOS}$を予測することにある. $\mathbb{E}[\hat{Y}_i^{OOS}|X_{i,2}^{OOS}=x_{i,2}^{OOS}]=\mathbb{E}[b_1+b_2x_i^{OOS}|X_{i,2}^{OOS}=x_{i,2}^{OOS}]=\beta_1+\beta_2x_i^{OOS}=\mathbb{E}[Y_i^{OOS}|X_{i,2}^{OOS}=x_{i,2}^{OOS}]$（∵OLSEの不偏性, $\mathbb{E}[\epsilon|X]=0$）なので, \rmfamily\mcfamily\bfseries{このOLS予測それ自体も不偏性を持つ}\mdseries と言える.\\

\paragraph{線形射影}
先ほど扱った期待値表記のOLS methodは, 線形射影係数の識別にも利用される. これはデータの\rmfamily\mcfamily\bfseries{最適な線形近似}\mdseries を与え, 実際に条件付き期待値が線形で無かったとしても成り立つ. OLSの理論を補強できるものとして考えられる. \\


\paragraph{誘導型と構造型}
回帰モデルにおいて, $\beta$ は必ずしも $\mathbf{X}$ の因果効果を意味する必要はない. まず, 因果効果として解釈できない場合, すなわち偶然変数同士が相関しており, $\mathbb{E}(Y|\mathbf{X})=\mu(\mathbf{X})$を満たすような関係を示す\rmfamily\mcfamily\bfseries{誘導型モデル}\mdseries を考える. この場合, 推定値$b$は, $\mathbf{X}$ の変化による$Y$への影響の程度を捉えるが, それは単なる統計的な共変動に過ぎない. 従って, $\mathbf{X}$ が他変数と相関していても（Ex. 内生変数）\rmfamily\mcfamily\bfseries{モデル推定自体は可能}\mdseries , その結果をもとに\rmfamily\mcfamily\bfseries{予測も可能}\mdseries . 今までのモデルは予測に注目しており, 誘導型モデルだったと言える. 一方, \rmfamily\mcfamily\bfseries{構造型モデル}\mdseries として回帰モデルを捉える場合, $\beta$の解釈は異なる. ここでは, $\beta$は$\mathbf{X}$の$Y$に与える\rmfamily\mcfamily\bfseries{直接的因果効果}\mdseries の大きさ, 即ち『$X_{i}$ が$1$単位増加したとき, 他全て（の変数）を一定に$Y$がどれだけ変化するか』として解釈される. 因果効果を正確に捉えることが目的なので, 因果推論を成立させる前提条件（Ex. $\mathbf{X}$ の外生性）が重要となる.\\

\paragraph{因果推論のための単回帰モデル・古典的仮定}
では, 実際に$\beta_2$が因果効果として考えるための仮定とは何だろうか. これ即ち\rmfamily\mcfamily\bfseries{単回帰モデルの古典的仮定}\mdseries である. 
\begin{align*}
  &\mathbf{(A1)}　 \mathbb{E}(\epsilon_i|X_{i, 2})=0\\
  &\mathbf{(A2)}　 (X_{i, 2}, Y_{i})　\text{for}　i=1, \dots, n　\text{はi.i.d.}\\
  &\mathbf{(A3)}　 (X_{i, 2}, \epsilon_{i})\text{は無限ではない4次のモーメントを持つ}\\
  &\mathbf{(A4)}　 \text{均一分散}: Var(\epsilon_i|X_{i, 2})=\sigma_\epsilon^{2}\\
  &\mathbf{(A5)}　 条件付き正規性: \epsilon_i|X_{i, 2} \sim \mathcal{N} (0, \sigma_\epsilon^{2})
\end{align*}
以上を満たすのが, 因果推論のための構造型単回帰モデルとして標準的なものである. このモデルでは, $\beta_2$は$X_{i,2}$の変化による\rmfamily\mcfamily\bfseries{因果効果}\mdseries として定義されることに留意せよ. 当然見せかけの因果関係や逆の因果関係は事前に排除されている. ここで, $X_{i,2}$ がランダムに割り当てられている（少なくともそのように見える）ならば, 構造モデルに必要な, 説明変数の誤差項との無相関, すなわち\textbf{外生性}を示唆する\rmfamily\mcfamily\bfseries{(A1)}\mdseries が満たされる. 数学的には, (A1)$\Rightarrow Cov(\epsilon_i, X_{i, 2})=0$であり, 対偶をとれば, $Cov(\epsilon_i, X_{i, 2})\neq 0\Rightarrow$ (A1) が崩れると表現可能. (A1)は, $b_2$が$\beta_2$の不偏推定量であることを確約している. 説明変数の漏れにより, $b_2$がもはや$\beta_2$の一致推定量でなくなる（不偏性もない）, つまり\rmfamily\mcfamily\bfseries{欠落変数バイアス}\mdseries (後述)による(A1)の崩れは, 後述の様々な推定法に繋がる議論である.\\

\paragraph{$b_2$の検定}
$b_2$の両側検定$H_0: \beta_2=\beta_{2,0}$について検討する. 先述の通り$b_2=\frac{s_{X,Y}}{s^{2}_{X}}$が$\beta_2$の推定量である. 説明変数$X$の母集団分布についての情報が未知な状況を考えると, $t$検定統計量は$T=\frac{b_2-\beta_{2,0}}{\sqrt{\hat{Var}(b_2)}}=\frac{b_2-\beta_{2,0}}{SE(b_2)}$である. $\epsilon|X \sim \mathcal{N}(0,\epsilon^2)$を仮定したfinite sampleのケースにおいては, $b_2$を分解してやり, $\sigma_X^2$が未知だったケースのように変形を行えば$T \sim t(n-2)$であることが分かる. 次に, 漸近理論から考察を行う. 今回は誤差項の正規性の仮定は置かず, $(X_i-\bar{X})\epsilon_i$にCLTが適応可能(と中級計量にはあるが\dots?), 言い換えればこの標準化標本平均に関する\rmfamily\mcfamily\bfseries{漸近正規性}\mdseries を仮定する. 仮定のもとで, 標本数が十分に大きければ, $T \overset{d}{\to} \mathcal{N}(0,1)$\rmfamily\mcfamily\bfseries{(未確認, 中級計量Ch3の後半参照)}\mdseries が成立し, ここでもt統計量の分布は標準正規分布で良く近似できることがわかった. 最後に信頼区間について考えよう. 再び(A5)をおけば, 分散が未知の場合$T \sim t(n-2)$であったことを利用して, $100(1-\alpha)$パーセント信頼区間$[b_2 - t_{1-\alpha / 2}(n-2) \hat{SE(b_2)}, b_2 + t_{1-\alpha / 2}(n-2) \hat{SE(b_2)}]$が構成できる.\\

\subsection{重回帰モデルの導入}
線形重回帰モデルも単回帰と同様に, 実際に条件付き期待値が$\mathbb{E}[Y|\mathbf{X}]=\mathbf{X}\beta$である（＝変数同士が実際に線形関係に従っている）と仮定する.議論の筋は単回帰のそれとおよそ同じであり, 違いは説明変数が複数ある事, それに伴い議論に行列を利用することである. \\

\paragraph{重回帰モデルの古典的仮定}
回帰係数ベクトル$\beta$が因果効果であることを以下が保証する. 
\begin{align*}
  &\mathbf{(A1)}　 \mathbb{E}(\epsilon_i|\mathbf{x}_{i})=0\\
  &\mathbf{(A2)}　 (\mathbf{x}_{i}, Y_{i})　\text{for}　i=1, \dots, n　\text{はi.i.d.}\\
  &\mathbf{(A3)}　 (\mathbf{x}_{i}, \epsilon_{i})\text{は無限ではない4次のモーメントを持つ}\\
  &\mathbf{(A4)}　 \text{フルランク(識別)}: rank(\mathbf{X})=K\\
  &\mathbf{(A5)}　 \text{均一分散}: Var(\epsilon_i|\mathbf{x}_{i})=\mathbb{E}(\epsilon_i^2|\mathbf{x}_{i})=\sigma^{2}\\
  &\mathbf{(A6)}　 条件付き正規性: \epsilon_i|\mathbf{x}_{i} \sim \mathcal{N} (0, \sigma^{2})
\end{align*}
(A1)はLIEより$\mathbb{E}[\epsilon_i]=0, Cov(\epsilon_i, x_{i,k})=0\forall k=1,\dots,K$であり, 説明変数の外生性を保証する. (A1),(A2)によって, 以下の関係が成立する.
\begin{align*}
  &\mathbf{E}[\epsilon | \mathbf{X}] = 
  \begin{pmatrix} 
    \mathbb{E}[\epsilon_1 |\mathbf{X}] \\ \vdots \\ \mathbb{E}[\epsilon_n |\mathbf{X}] 
  \end{pmatrix} 
  = 
  \begin{pmatrix} 
    \mathbb{E}[\epsilon_1 |\mathbf{x}_1] \\ \vdots \\ \mathbb{E}[\epsilon_n |\mathbf{x}_n] 
  \end{pmatrix} 
  = \mathbf{0}\\
  &\mathbf{E[Y|X]}=\mathbf{X}\beta + \mathbf{E}[\epsilon | \mathbf{X}] = \mathbf{X}\beta\\
  &Cov(\epsilon_i, \epsilon_j | \mathbf{X})=\mathbb{E}(\epsilon_i \epsilon_j | \mathbf{X})=\mathbb{E}(\epsilon_i \epsilon_j | \mathbf{x}_i, \mathbf{x}_j)=\mathbb{E}(\epsilon_i | \mathbf{x}_i) \mathbb{E}(\epsilon_j |\mathbf{x}_j)=0
\end{align*}
(A3)は漸近理論のために必要な仮定であり, (A4)は説明変数間に完全な線形関係（多重共線性）がないことを保証しており, $rank(\mathbf{X}^T\mathbf{X})=rank(\mathbf{X})=K$も成立する. (A4)が崩れた場合, 回帰係数は無限個解を持つ(不定)ため, 識別が不可能となる. 特にダミー変数について, この状況は\rmfamily\mcfamily\bfseries{ダミー変数の罠(dummy variable trap)}\mdseries と呼ばれる. (A1), (A2), (A5)より, $\mathbf{Var}(\epsilon | \mathbf{X})=\mathbf{E}[\epsilon\epsilon^T| \mathbf{X}]=\sigma^2\mathbf{I}$. さらに全分散の法則より, $\mathbf{Var}(\epsilon)=\mathbf{E}[\mathbf{Var}(\epsilon | \mathbf{X})]+\mathbf{Var}(\mathbf{E}[\epsilon | \mathbf{X}])=\sigma^2\mathbf{I}$, LIEより$\mathbf{E}[\epsilon]=\mathbf{0}$を得て直接計算しても確認可能である. (A1), (A2), (A5), (A6)から, $\epsilon|\mathbf{X} \sim \mathcal{N} (\mathbf{0}, \sigma^{2}\mathbf{I})$.\\

\paragraph{$\beta$の推定}
今, $(\mathbf{x}_{1}, Y_1), \dots, (\mathbf{x}_{n}, Y_n)$ と$n$個の無作為標本が与えられ, その\rmfamily\mcfamily\bfseries{実現値}\mdseries$(\mathbb{x}_{1}, y_1), \dots, (\mathbb{x}_{n}, y_n)$が判明している下で, 以下の残差平方和のminimizerとしてOLS推定値$\mathbf{b}$を決定する.
\begin{equation*}
  S(\mathbf{b}_{0})=\sum_{i = 1}^{n} e_{i,0}^{2}=\mathbf{e}_{0}^{T}\mathbf{e}_{0}=(\mathbf{y}-\mathbb{X}\mathbf{b}_{0})^{T}(\mathbf{y}-\mathbb{X}\mathbf{b}_{0})
\end{equation*}
以上よりOLS推定値$\mathbf{b}=(\mathbb{X}^{T}\mathbb{X})^{-1}\mathbb{X}^{T}\mathbf{y}$を得られる. 一般に, $\hat{\mathbf{b}}=(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{X}^{T}\mathbf{Y}$がOLS推定量.\\

\rmfamily\mcfamily\bfseries{補足:OLSEの導出}\mdseries　行列計算の練習にOLS推定値の導出を確認しよう. $S(\mathbf{b}_{0})=\sum_{i = 1}^{n} e_{i,0}^{2}=\mathbf{e}_{0}^{T}\mathbf{e}_{0}=(\mathbf{y}-\mathbb{X}\mathbf{b}_{0})^{T}(\mathbf{y}-\mathbb{X}\mathbf{b}_{0})=(\mathbf{y}^{T}-\mathbf{b}_{0}^{T}\mathbb{X}^{T})(\mathbf{y}-\mathbb{X}\mathbf{b}_{0})=\mathbf{y}^{T}\mathbf{y}-\mathbf{b}_{0}^{T}\mathbb{X}^{T}\mathbf{y}-\mathbf{y}^{T}\mathbb{X}\mathbf{b}_{0}+\mathbf{b}_{0}^{T}\mathbb{X}^{T}\mathbb{X}\mathbf{b}_{0}=\mathbf{y}^{T}\mathbf{y}-2\mathbf{y}^{T}\mathbb{X}\mathbf{b}_{0}+\mathbf{b}_{0}^{T}\mathbb{X}^{T}\mathbb{X}\mathbf{b}_{0}$, 最後の変形は第$3,4$項がスカラーであることによる. 正規方程式は以下のように変形できる. $\mathbf{0}=\frac{\partial S(\mathbf{b}_{0})}{\partial\mathbf{b}_0}|_{\mathbf{b}_0=\hat{\mathbf{b}}_*}=-2\frac{\partial S(\mathbf{b}_{0})}{\partial\mathbf{b}_0}\mathbf{y}^{T}\mathbb{X}\mathbf{b}_{0}|_{\mathbf{b}_0=\hat{\mathbf{b}}_*}+\frac{\partial S(\mathbf{b}_{0})}{\partial\mathbf{b}_0}\mathbf{b}_{0}^{T}\mathbb{X}^{T}\mathbb{X}\mathbf{b}_{0}|_{\mathbf{b}_0=\hat{\mathbf{b}}_*}=-2(\mathbf{y}^{T}\mathbb{X})^{T}+(\mathbb{X}^{T}\mathbb{X}+(\mathbb{X}^{T}\mathbb{X})^{T})\hat{\mathbf{b}}_*=-2\mathbb{X}^{T}\mathbf{y}+2\mathbb{X}^{T}\mathbb{X}\hat{\mathbf{b}}_*$. $\mathbb{X}^{T}\mathbf{y}=\mathbb{X}^{T}\mathbb{X}\hat{\mathbf{b}}_*$から, $(\mathbb{X}^{T}\mathbb{X})^{-1}(\mathbb{X}^{T}\mathbb{X})\hat{\mathbf{b}}_*=\hat{\mathbf{b}}_*=(\mathbb{X}^{T}\mathbb{X})^{-1}\mathbb{X}^{T}\mathbf{y}$.\\

\paragraph{$\mathbf{y}$の予測値}
次に, 無作為標本の実現値が与えられ, OLS推定値を用いて導かれる内生変数の予測値に関連する性質を考える. 予測値$\hat{y}_i=\mathbb{x}_i^{T}\mathbf{b}$, 残差$e=\mathbf{y}-\hat{\mathbf{y}}$とする. このとき, 正規方程式$\mathbb{X}^T(\mathbb{y}-\mathbb{X}\mathbf{b})=\mathbf{0}$より$\mathbb{X}^T\mathbf{e}=\mathbf{0}$である. 特に, 一般的な重回帰モデルでは$\mathbf{X}$の一列目が$1$であることから, $\frac{1}{n}\sum_{i=1}^{n}e_i=\bar{e}=0$, $s_{e, x_k}=0　\forall k=2,\dots,K$, $\bar{y}=\bar{\mathbb{x}}^{T}\mathbf{b}$($\bar{\mathbb{x}}$は説明変数の標本平均ベクトル), $\bar{\hat{y}}=\hat{y}$が成り立つ. 決定係数についても単回帰と同様で, $R^2=\frac{ESS}{TSS}=1-\frac{SSR}{TSS}=1-\frac{\mathbf{e}^T\mathbf{e}}{\mathbf{y}^T\mathbf{y}-n\bar{y}^2}=(\hat{corr}(y_i,\hat{y_i}))^2$. 説明変数が増えれば$R^2$は必ず上昇する性質がある. この問題を解決する為に\rmfamily\mcfamily\bfseries{調整済み決定係数}\mdseries $\bar{R}^2$も存在し, $\bar{R}^2=1-\frac{n-1}{n-K}(1-R^2)$. ただ決定係数は予測の当てはまりを示すのみで, 低いからと言って特に因果推論に用いる場合には必ずしもモデルが悪いわけではない. また, 予測に関しても線形射影としてのOLSの有用性を考えれば, データが非線形に生成されても, 決定係数は悪くなるが依然線形近似としての意義はある. 以上の問題からか, 末石計量では決定係数の記載が一切ない.\\

\section{回帰モデルの性質}
\subsection{Finite Sampleの性質}
\paragraph{OLS推定量の性質}
まず, 不偏性について考えよう. \\

\paragraph{ガウスマルコフの定理(Gauss-Markov Theorem)}
\rmfamily\mcfamily\bfseries{定理}\mdseries : 古典的仮定下では, OLS推定量$\mathbf{b}$は線形不偏推定量のうち最も効率的である. まず効率性の定義を確認しよう. 二つの不偏推定量$\hat{\theta}$と$\tilde{\theta}$を考えると, $Var(\mathbf{a}^T\tilde{\theta})-Var(\mathbf{a}^T\hat{\theta})=\mathbf{a}^T[Var(\tilde{\theta})-Var(\hat{\theta})]\mathbf{a} \geq  0　\forall\mathbf{a}\neq \mathbf{0}$ ならば, $\hat{\theta}$が効率的という. つまり共分散行列の差が非負値定符号行列である. 共分散行列の差は対称行列より, 効率的であることは, その全主小行列式（Principal Minors, PM）が非負であることと同値. また, 全ての対角成分, 即ち各々の分散が他の推定量に比べ最低限大きくないことが必要条件である. 1次元の推定量の場合, 効率的であることは分散が大きくないことと同値で, 非負定符号行列を用いた上記の定義はその一般化である. ガウスマルコフの定理は, この効率性の定義を利用して, 全ての不偏推定量$\mathbf{b}_0$に関して, $\mathbf{Var}[\mathbf{b}_0|\mathbf{X}] - \mathbf{Var}[\mathbf{b}|\mathbf{X}]$が非負値定符号行列と主張する定理だと換言できる.\\

\section{プログラム評価}
我々が関心を持つ対象が, $X$が一単位変化したときの$Y$への\rmfamily\mcfamily\bfseries{因果効果, 処置効果}\mdseries とする. 個人$i$が処置群に含まれれば$X_i=1$, 対照群に含まれれば$X_i=0$をとる確率変数を考える. 個人$i$の処置効果は, $te_i=Y_{i,1}-Y_{i,0}=Y_{i}(X_i=1)-Y_{i}(X_i=0)$だが, どちらかは反実仮想であり, 従って観察不可能. そこで\rmfamily\mcfamily\bfseries{平均処置効果, ATE}\mdseries を考えると, これは$\mathbb{E}[Y_{i,1}]-\mathbb{E}[Y_{i,0}]$で与えられる. また, 処置群への平均処置効果(ATET)は$\mathbb{E}[Y_{i,1}|X_i=1]-\mathbb{E}[Y_{i,0}|X_i=1]$, 対照群への平均処置効果(ATENT)は$\mathbb{E}[Y_{i,1}|X_i=0]-\mathbb{E}[Y_{i,0}|X_i=0]$である. しかし, 現状どれも観察不可能な項が含まれる. $\mathbb{E}[Y_{i,1}|X_i=1]-\mathbb{E}[Y_{i,0}|X_i=0]$は観測可能で, かつ一見因果効果を捉えているように思えるが\dots?
\begin{equation*}
  \mathbb{E}[Y_{i,1}|X_i=1]-\mathbb{E}[Y_{i,0}|X_i=0]=ATE+\underset{\text{selection bias}}{\underbrace{\mathbb{E}[Y_{i,0}|X_i=1]-\mathbb{E}[Y_{i,0}|X_i=0]}}+\underset{\text{heterogeneous selection bias}}{\underbrace{(1-\pi)(ATET-ATENT)}}
\end{equation*}
ここで, $\pi$は処置群に含まれる確率である. 因果効果を議論する際, 処置群と対照群がランダムに割り当てられていない限りは, セレクションバイアスに注意する必要性が明らかとなった.\\

\paragraph{ランダム比較実験, RCT}
では, どのような条件の下で$\mathbb{E}[Y_{i,1}|X_i=1]-\mathbb{E}[Y_{i,0}|X_i=0]=ATE$は保証されるだろうか? この十分条件を満たすのが既に幾度か言及している\rmfamily\mcfamily\bfseries{ランダム比較実験, RCT}\mdseries である. 処置群と対照群がランダムに割り当てられているこの状況下では, 上記の式が$\mathbb{E}[Y_{i,1}|X_i=1]=\mathbb{E}[Y_{i,1}|X_i=0]=\mathbb{E}[Y_{i,1}]$, $\mathbb{E}[Y_{i,0}|X_i=1]=\mathbb{E}[Y_{i,0}|X_i=0]=\mathbb{E}[Y_{i,0}]$となることで満たされる. また, 各人で同一の固定処置効果を仮定した場合, 単回帰の傾きのOLSEがATEに整合することも知られており, この結果を補強している. 詳細は次の通り. $Y_{i,1}=\tau + Y_{i,0}$より, $Y_i=Y_{i,0}+(Y_{i,0}-Y_{i,1})X_i=Y_{i,0}+\tau X_i$で, $Y_{i,0}=\mathbb{E}[Y_{i,0}]+\epsilon_{i,0}$とすれば$Y_i=\mathbb{E}[Y_{i,0}]+\tau X_i+\epsilon_{i,0}=\beta_1+\beta_2X_i+\epsilon_i$と単回帰モデルの形になる. (A1)が成立している, 即ち$\mathbb{E}[\epsilon_i|X_i]=\mathbb{E}[\epsilon_{i,0}|X_i]=0$が成り立つならば, すなわちRCTの仮定の下では, OLSの$\beta_2$への不偏性は保証されている. 特にこの場合$\tau$の推定値が単回帰モデルの形でも正確に因果効果を意味することが分かるだろう. 個人の処置効果が不均一でもこの議論は行える. $Y_{i,1}=\mathbb{E}[Y_{i,1}]+\epsilon_{i,1}$とすると, $te_i=\tau_{ATE}+[\epsilon_{i,1}-\epsilon_{i,0}]$. 同様に単回帰モデルの形にすると, $\beta_2=\tau_{ATE}$, $\epsilon_i=\epsilon_{i,0}+[\epsilon_{i,1}-\epsilon_{i,0}]X_i$となり, RCTの仮定の下では$\mathbb{E}[\epsilon_i|X_i]=0$が成立する. しかし不均一分散であることに注意. 他にも, 複数の処置を入れた場合や, 処置が連続的の線形モデル(限界効果が一定)などの拡張がある.\\

\section{コントロール変数}
我々の関心は, ある変化によりもたらされた帰結＝\rmfamily\mcfamily\bfseries{因果効果の推定}\mdseries にあるとする. 先述の通り, 自然実験で得られたデータとは違い, 観測データには様々なノイズが介在しうる. 因果推論の文脈における回帰分析の主要な役割は, 観測データからノイズを除去して因果効果のみを取り出すことにある. その目的のためには, 全変数を平等に扱う必要はない. ここで導入されるのが\rmfamily\mcfamily\bfseries{コントロール変数}\mdseries と\rmfamily\mcfamily\bfseries{代理変数}\mdseries の概念である.  コントロール変数の定義としては以下で挙げるようなものがある. 1: 回帰に含まれたとき，誤差項を興味のある説明変数と無相関にするもの. 2: 値を一定に保つと，興味のある説明変数が「あたかも」無作為に割り当てられている状態を作り出せるもの. 3: 値が同じ個人間では，興味のある説明変数が, 省略された決定因子と相関しないようなもの. コントロール変数をモデルに導入することで, 後述する欠落変数バイアスの発生を防ぎ, 興味のある説明変数のパラメータを正確に推定可能にしている. ある要素が観測不可能である時に利用されるのが, その要素と相関がある\rmfamily\mcfamily\bfseries{代理変数(proxy variables)}\mdseries である. コントロール変数の文脈での代理変数は, 観測不可能な制御対象がある際, 対象と相関するが, 自身は因果効果を持たないものである.\\

\paragraph{欠落変数と因果推論}
古典的仮定を満たす線形モデル$Y=\beta_1+\beta_2X_{2}+\beta_3X_{3}+\tilde{\epsilon}$に従って生成される観測データから, $X_2$による因果効果$\beta_2$を測定することを目標として考える. $Y$を$1, X_{2}$に回帰してもその測定は可能なのだろうか? $\mathbb{E}[Y|X_{2}]=\beta_1+\beta_2X_{2}+\beta_3\mathbb{E}[X_{3}|X_{2}]+\mathbb{E}[\tilde{\epsilon}|X_{2}]$で, 真の回帰モデルにおける(A1)より$\mathbb{E}[\tilde{\epsilon}|X_{2}]=\mathbb{E}[\mathbb{E}[\tilde{\epsilon}|X_{2}, X_{3}]|X_{2}]=0$. ここで, $X_3=\delta_1+\delta_2 X_{2} + \eta $, $\mathbb{E}[\eta|X_2]=0$, $\delta_2 \neq 0$と仮定すれば, $\mathbb{E}[Y|X_{2}]=\beta_1+\beta_2X_{2}+\beta_3\mathbb{E}[\delta_1+\delta_2 X_{2} + \eta|X_{2}]=(\beta_1+\beta_3\delta_1)+(\beta_2+\beta_3\delta_2)X_{2}$である. $Y=\mathbb{E}[Y|X_{2}]+\epsilon=(\beta_1+\beta_3\delta_1)+(\beta_2+\beta_3\delta_2)X_{2}+\epsilon$から, $\mathbb{E}[\epsilon|X_2]=0$ゆえ, (A1)はこの仮定下では満たせるように構成できた. しかしここで推定の対象である, $X_2$の切片である$\beta_2+\beta_3\delta_2$は真の$\beta_2$と異なり, モデルは因果効果の測定には利用不能.\\

\rmfamily\mcfamily\bfseries{Ex. 出生時体重の因果推論}\mdseries　幼児の健康状態を決定する重要な要素として出生児体重がある. 今回はこの数値$weight$に関する因果推論を行うことを目標として定めよう. $weight$を減少させる因果効果を持つ要素の一つとして, 母親の妊娠時喫煙が考えられる. 今回は, 喫煙していれば$1$を, してなければ$0$をとるダミー変数$smoke$を導入した, 単回帰モデル$weight = \beta_1 + \beta_2 smoke + \epsilon$を考える. このモデルは因果効果を正しく推定できるだろうか?　\rmfamily\mcfamily\bfseries{解答}\mdseries　他に因果効果をもつ要素として, 所得も考えられる. これらの効果を制御しなければ不可能. ただし体重の予測は依然可能.\\

\paragraph{欠落変数バイアス}
再度, 古典的仮定を満たす線形モデルに従って生成される観測データ$Y_i=\beta_1+\beta_2X_{i,2}+\beta_3X_{i,3}+\tilde{\epsilon}_i$, $i=1,\dots,n$から, $X_2$による因果効果測定を目標とする. $Y_i$を$1, X_{i,2}$に回帰しても, $Y_i=\beta_1+\beta_2X_{i,2}+\epsilon_i$ with $\epsilon_i=\beta_3X_{i,3}+\tilde{\epsilon}_i$で, 誤差項に欠落変数の影響を全て格納し, 正確に因果効果を測れるような状況を作り出すため, 如何なる条件があるのかを一般化する. OLSEの公式を適用すると, $b_2^\prime =\frac{s_{X_2,Y}}{s_{X_2}^2}=\frac{\frac{1}{n-1}\sum{(X_{i,2}-\bar{X_{2}})(Y_{i}-\bar{Y})}}{\frac{1}{n-1}\sum{(X_{i,2}-\bar{X_{2}})^2}}=\beta_2+\frac{\frac{1}{n-1}\sum{(X_{i,2}-\bar{X_{2}})(\epsilon_i-\bar{\epsilon_i})}}{\frac{1}{n-1}\sum{(X_{i,2}-\bar{X_{2}})^2}}=\beta_2+\frac{\frac{1}{n-1}\sum{(X_{i,2}-\bar{X_{2}})\epsilon_i}}{\frac{1}{n-1}\sum{(X_{i,2}-\bar{X_{2}})^2}}$ $(\because Y_{i}-\bar{Y}=(\beta_1+\beta_2X_{i,2}+\epsilon_i)-(\beta_1+{\beta_2}\bar{X_{2}}+\frac{1}{n}\sum{\epsilon_i})={\beta_2}(X_{i,2}-\bar{X_{2}})+(\epsilon_i-\bar{\epsilon_i}), \sum{(X_{i,2}-\bar{X_{2}})\bar{\epsilon}}=\bar{\epsilon}\sum{(X_{i,2}-\bar{X_{2}})}=0)$. $n$が十分大きければ, LLNより$\frac{1}{n-1}\sum{(X_{i,2}-\bar{X_{2}})^2} \overset{p}{\to} Var(X_2)$, $\frac{1}{n-1}\sum{(X_{i,2}-\bar{X_{2}})(\epsilon_i-\bar{\epsilon_i})} \overset{p}{\to} Cov(X_2, \epsilon)$. このため, $b_2^\prime \overset{p}{\to} \beta_2+\frac{Cov(X_2, \epsilon)}{Var(X_2)}$である. ここで, (A1)$\mathbb{E}[\epsilon | X_{2}]=0 \implies Cov(X_2, \epsilon) = 0$は一致性$b_2^\prime \overset{p}{\to} \beta_2$の十分条件. 不偏性も(A1)を仮定すれば, $X_{2}$についての条件付期待値をとりLIEより確認可能. $\epsilon_i=\beta_3X_{i,3}+\tilde{\epsilon}_i$を利用して更に考察を進めてみよう. $Cov(X_2, \epsilon)=Cov(X_2, \beta_3X_{3}+\tilde{\epsilon})=\beta_3Cov(X_2, X_{3})+Cov(X_2, \tilde{\epsilon})$. 真の構造型回帰モデルの(A1)より$\mathbb{E}[\tilde{\epsilon} | X_{2}, X_{3}]=0$が成立し, LIEより$Cov(X_2, \tilde{\epsilon})=\mathbb{E}[(X_2-\bar{X_2})(\tilde{\epsilon}-\bar{\tilde{\epsilon}})]=\mathbb{E}[\mathbb{E}[(X_2-\bar{X_2})(\tilde{\epsilon}-\bar{\tilde{\epsilon}})]|X_{2}, X_{3}]=\mathbb{E}[(X_2-\bar{X_2})\mathbb{E}[\tilde{\epsilon}-\bar{\tilde{\epsilon}}|X_{2}, X_{3}]]=0$. ゆえに$Cov(X_2, \epsilon)=\beta_3Cov(X_2, X_{3})$で, 以下のように整理される.
\begin{equation*}
  b_2^\prime \overset{p}{\to} \beta_2+ \underset{\text{omitted variable bias}}{\underbrace{\beta_3\frac{Cov(X_2, X_3)}{\sigma_{X_2}^2}}}
\end{equation*}
RCTの仮定下では$X_2$はランダムに割り当てられているため, $b_1^\prime$は一致性と不偏性を満たすが, $\beta_3 \neq 0 \text{ nor } Cov(X_2, X_{3})\neq 0$の時には一致性を持たず,このズレのことを欠落変数バイアス(omitted variable bias)と呼ぶ. 補足できていない欠落変数の因果効果が, 相関する変数$X_2$を経由して被説明変数に影響を与えており, 推定のズレの方向は相関に一致する. この時, 先述の通り$ Cov(X_2, \epsilon) \neq 0 \implies \mathbb{E}[\epsilon | X_{2}] \neq 0$で\rmfamily\mcfamily\bfseries{内生性}\mdseries によって(A1)が崩れていることを確認せよ.\\

\paragraph{コントロール変数}
古典的仮定を満たす線形モデル$Y_i=\beta_1+\beta_2X_{i,2}+\beta_3X_{i,3}+\epsilon_i$に従って生成される観測データから, $X_2$による因果効果を測定することを目標として考える. $Y_i$を$1, X_{i,2}$に回帰すると, $\beta_3 \neq 0 \text{ nor } Cov(X_2, X_{3})\neq 0$の場合は, 欠落変数バイアスから正確に因果効果を測定できない. コントロール変数として$X_{i,3}$を入れてやり, $1, X_{i,2}, X_{i,3}$に回帰すれば, $E[\epsilon_i | X_{i,2}, X_{i,3}]=0$で$b_2, b_3$は共に一致推定量となり, 正しく因果効果を測定できる.\\

\paragraph{冗長なコントロール変数}
コントロール変数を不用意に追加することは, 不偏性には影響を及ぼさずとも, 推定量の分散を大きくし, 精度を悪化させることが知られている. これを詳しく見よう. $Y=\beta_1+\beta_2X_{2}+\tilde{\epsilon}$ を, 余分に説明変数を付け加えた$Y=\beta_1+\beta_2X_{2}+\beta_3X_{3}+\epsilon$で誤って推定する場合を考える. $\beta_3=0$とすると, 欠落変数バイアスは発生せず, ${E}[\epsilon | X_{2}, X_{3}]=0$が成立していれば誤ったモデルでも真のパラメータとの一致性が保たれる. 大標本においては, $b_2 \overset{a}{\sim} \mathcal{N}(\beta_2, \sigma_{b_2}^2)$, where $\sigma_{b_2}^2=\frac{1}{n}(\frac{1}{1-\rho_{X_{2}, X_{3}}^2})\frac{\sigma_\epsilon^2}{\sigma_{X_{2}}^2}$であることが知られている. この結果より, 冗長な変数と元説明変数との間に強い相関$\rho_{X_{2}, X_{3}}$があるほど分散が大きくなり, 推定は悪化することが分かった.\\

\paragraph{変数選択}
一方RCTの仮定下で議論を進めれば, $\rho_{X_{2}, X_{3}}=0$, $Var({\epsilon})>Var(\tilde{{\epsilon}})$より, 適切な変数追加なら, 予測精度を向上させることも確認できる. 変数追加について慎重になるべきケースはまだある. 現在の説明変数の因果効果を媒介する新たな説明変数は, 因果効果を推定出来ないため入れるべきではない. このような変数を\rmfamily\mcfamily\bfseries{悪いコントロール(bad control)}\mdseries とよぶ.\\

\paragraph{議論の一般化}
欠落変数の因果推論への影響を一般化しよう. 類似の議論は北村の応用ミクロ計量(2002)-第二講(\url{https://www.ier.hit-u.ac.jp/~kitamura/index_j.html})にて展開されている, さらに言えば元文献はWooldridge (2002, Ch.4) らしいが. 構造モデルが$\mathbb{E}[y|x_2, \dots, x_k, q]=\beta_1+\beta_2x_2+\dots+\beta_Kx_K+\gamma q$ with $\gamma \neq 0$で与えられるとする. これを書き直せば, $y=\beta_1+\beta_2x_2+\dots+\beta_Kx_K+\gamma q+\tilde{\epsilon}$で, $\mathbb{E}[\tilde{\epsilon}|x_2, \dots, x_k, q]=0$より(A1)を満たす. ここで, 観測できない\rmfamily\mcfamily\bfseries{潜在変数}\mdseries $q$をモデルに直接入れ込むことは不可能であるため, 実際に推定する際のモデルは$y=\beta_1+\beta_2x_2+\dots+\beta_Kx_K+\epsilon$ where $\epsilon = \gamma q+\tilde{\epsilon}$. このモデルでの因果推論が可能, つまり欠落変数バイアスがないのは, $q$が$\mathbf{x}$それぞれと無相関である場合に限られる. 仮定のもとで$q$を$\mathbf{x}$に回帰すると$q=\delta_1+\delta_2x_2+\dots+\delta_Kx_K+r$となり, $Cov(x_j, r)=0 \forall j$. 代入すると, $y=(\beta_1+\gamma \delta_1)+(\beta_2+\gamma \delta_2)x_2+\dots+(\beta_K+\gamma \delta_K)x_K+\tilde{\epsilon}+\gamma r$, with $Cov(x_j,\tilde{\epsilon}+\gamma r)=0 \forall j$を得た. 欠落変数バイアスの部分と同様の議論によって, $b_k \overset{p}{\to} \beta_k +\gamma \delta_k$ で一致性の崩れを確認できる. この場合の欠落変数バイアスを防ぐ方法が\rmfamily\mcfamily\bfseries{代理変数}\mdseries の利用だ. この際代理変数が満たすべき条件は以下.\\

\rmfamily\mcfamily\bfseries{1. 代理変数が構造モデル中で重複}\mdseries : $z$を$q$の代理変数として, $\mathbb{E}[Y|\mathbf{x},q,z]=\mathbb{E}[Y|\mathbf{x},q]$が成立する. つまり$Y$の説明に$z$が無関係であること.\\

\rmfamily\mcfamily\bfseries{2. $q$と$x_j$は$z$制御下で無相関}\mdseries : $q=L[q|1, \mathbf{x}, z]=L[q|1, z]=\delta_1 + \delta_2z+r$, where $\delta_2\neq 0, \mathbb{E}[r]=0, Cov(z, r)=0$. 同値の表現として$Cov(x_j, r)=0 \forall j$もある.\\

上記の条件のもと, 構造モデルは$Y=(\beta_1+\gamma\delta_1)+\beta_2x_2+\beta_3x_3+\dots+\beta_Kx_K+\gamma\delta_2z+(\gamma r + v)$となり$\mathbf{x}$でのOLS推定は一致性を保っている.\\

\paragraph{コントロール変数の文脈における代理変数}
再び構造モデル$Y=\beta_1+\beta_2X_{2}+\beta_3X_{3}+\tilde{\epsilon}$での代理変数の活用法を考える. 古典的仮定を満たす上記の線形モデルに従い生成される観測データから, $X_2$による因果効果の測定を目標として考える. ただし$X_{3}$は観測不能. $1, X_{2}$に回帰すると, 欠落変数バイアスから正確に因果効果を測定できないことは先述の通り. ここで, $X_{3}$と相関する, しかし自身は因果効果を持つ必要のない\rmfamily\mcfamily\bfseries{代理変数}\mdseries $W$をモデルに入れ, $Y=\beta_1+\beta_2X_{2}+\beta_3W+\epsilon$と書き換え, 以下代理変数の条件付けを言い換えてコントロールの正統性を確認する.\\

\rmfamily\mcfamily\bfseries{その1. 代理変数の条件利用}\mdseries　先述の代理変数の$2$条件を適応させよう. 条件1の言い換えとして, $Cov(W, \tilde{\epsilon})=0$を, 条件2を利用して, $X_3=L[X_3|1, X_2, W]=L[X_3|1, W]=\delta_1 + \delta_2W+r$, $\delta_2\neq0$と仮定する. LIEより$\mathbb{E}[r|X_2, W]=0$. 代入すると$Y=(\beta_1+\beta_3\delta_1)+\beta_2X_{2}+\beta_3\delta_2W+\tilde{\epsilon}+\beta_3r$, $\mathbb{E}[\tilde{\epsilon}+\beta_3r|X_2, W]=0$を得る. この時$b_2 \overset{p}{\to}\beta_2$で因果効果を一致推定できた.\\

\rmfamily\mcfamily\bfseries{その2. 条件付平均独立の仮定}\mdseries　(A1)を以下の\rmfamily\mcfamily\bfseries{条件付平均独立}\mdseries に置き換えてもよい: $E[\epsilon | X_{2}, W]=E[\epsilon| W]$. この仮定が$\beta_2$の因果推論の正確性を保証することを確かめるため, $Y=\beta_1+\beta_2X_{2}+\beta_3W+\epsilon$において$E[\epsilon | X_{2}, W]=E[\epsilon|W]=\gamma_1+\gamma_2W, \gamma_2\neq0$と線形関係で条件付平均独立の仮定を満たすよう表現しよう. 更に, $\epsilon$を$X_{2}, W$に回帰して, $\epsilon=E[\epsilon|X_{2}, W]+v$とすると, LIEより, $E[v|X_{2}, W]=0$である. モデルを明示的に示すと, $Y=\beta_1+\beta_2X_{2}+\beta_3W+\epsilon=\beta_1+\beta_2X_{2}+\beta_3W+\gamma_1+\gamma_2W+v=(\beta_1+\gamma_1)+\beta_2X_{2}+(\beta_3+\gamma_2)W+v$である. このとき, $\beta_2$は依然因果効果として解釈でき, $b_2$は一致推定量であるので回帰分析の目標は果たされた. $\beta_3+\gamma_2$はバイアスがあっても, そもそも建付けの時点から, 回帰に入れていない変数から$W$を経由して被説明変数が変化していることを想定しているために問題ない.\\

\rmfamily\mcfamily\bfseries{Ex. 教育の賃金への因果効果}\mdseries　賃金への影響を与える要因が, 教育年数, 就業年数, そして能力のみであると考えよう. このとき求めたいのは, $\frac{\partial \mathbb{E}(wage|edu, exper, abil)}{\partial edu}$ で, コントロール変数ベクトル$\mathbf{C}=(exper, abil)$だが能力は\rmfamily\mcfamily\bfseries{観測不可能}\mdseries . 回帰モデルを考えると, 就業年数はコントロール変数としてモデルに入れられる他, 能力$abil$に相関する代理変数として$IQ$もコントロール変数に採用できる. すなわち$\mathbb{E}(wage|edu, exper, IQ)$を考えればよい.\\

\section{内部妥当性} 
統計的推測の妥当性は, 内部妥当性と外部妥当性の二つに大別される. 内部妥当性とは, 因果効果に関する統計的推測が調査された母集団と設定に対して有効であることを言う. 一方で外部妥当性は, 推論と結論が, 他の集団や設定にも一般化可能であることを意味する. 今回は内部妥当性に焦点を当てて議論を進めよう. 回帰モデルの古典的が外れた時に内部妥当性が崩れる恐れがあるわけだが, さらに, 推定量の不偏性や一致性への影響と, 標準誤差への影響とそれに伴う予測精度の悪化の二つにグループ分けが可能である. 前者の例としては先述の欠落変数バイアスを始めとして, モデルの誤った関数特定化, 測定誤差, セレクションバイアス, 同時性がある. 後者の例としては, 不均一分散や誤差項の内生性などが挙げられる.\\

\paragraph{測定誤差}
説明変数に測定誤差が生じている場合, (A1)が崩れ因果推論が行えなくなる. 例えば誤差$w$が分散$\sigma_w^2$でi.i.dで$K=2$のケースをかんがえれば, $b_2 \overset{p}{\to} \beta_2 - \beta_2\frac{\sigma_w^2}{Var(\tilde{X_2})}$ で過少推定となる. この解決法には操作変数法が用いられる. \\

\paragraph{セレクションバイアス}
データの可用性が従属変数の値に関連する選択プロセスによって影響を受ける場合に発生する. 誤差項と回帰変数が相関し(A1)が崩れ, OLS推定の不偏性が崩れる.\\

\rmfamily\mcfamily\bfseries{Ex. 教育の賃金への因果効果}\mdseries　研究者が, 就職している大学卒業生のランダム標本を調査し, 教育の収益を推定するため賃金と教育年数の回帰をおこなうことを考える. しかし, ここでのサンプルは就業者に限定されている. 就業するか否かを決定する, 教育, 経験, 能力, 運などは, 稼得能力の決定要因に似通っているため, セレクションバイアスの発生を疑う必要がある.\\

\paragraph{同時性}
変数が相互に因果効果を与えあう場合に起こる問題で, (A1)が崩れる. 
たとえば, 生徒と教師の比率はテストのスコアに影響するが, 同時に, 政府の取り組みによりテストスコアが低い学区で教師の雇用が補助されるため, テストスコアも生徒と教師の比率に影響する. なお, この問題も操作変数法で解決可能である. 詳しくは操作変数法の項を参照せよ.\\

\paragraph{系列相関, 誤差項の内生性}
誤差が観測値全体に渡り相関する場合(A2)が破られる. 通常時系列, パネルデータで発生する事象. 観測値全体にわたる誤差の相関によって, OLSEの不偏性や一致性が崩れないが, 標準誤差が\rmfamily\mcfamily\bfseries{望ましい有意水準の信頼区間を生成しない}\mdseries 点で不正確.\\

\section{制約とF検定}
先ず(A6)条件付き正規性を仮定した下での議論を行う. F値の導出には$2$つの手法がある. 一つ目は制約式が成立する場合を帰無仮説と置いたとき制約からどれほどずれがあるのかを調べる方法, 二つ目は決定係数を制約ありモデルと制約なしモデルで比較する方法である. RやStataで表示される$F$値は帰無仮説として定数のみ回帰を考えた際の値で, $F(K-1, n-K)$に従うことに注意せよ. 次に, 正規性を外した場合の漸近分布を探ろう. この時, $\mathbf{b}$の漸近正規性を利用することで$W=F J\overset{d}{\to}\chi ^2(J)$であることが知られており, この結果は不均一分散のもとでも成立する.\\

\section{構造推定}
経済理論から推定された関数形と, 通常の線形モデルを比較しどちらが適切であるかを考察しよう. 通常の回帰モデルから外れた概念として, ダミー変数と対数変換, そして多項回帰モデルを本節では導入する. ダミー変数とは, $0, 1$のどちらか二値を取る変数である. 例えば季節ダミーはコントロール変数かつダミー変数である. 序数的な意味のみを持つ量的変数に関して気を付けなければいけないのは, それぞれの水準を個別にダミー変数として設定しなければならないことである. というのも, 一つの説明変数で表現を行うことは, 暗黙に一貫した基数的な被説明変数への影響を仮定することだからである. 今までは説明変数に関して線形なモデルを考えてきたが, 我々はパラメータに関して線形での, 以下のようなモデルのヴァリエーションを更に考える.
\begin{align}
  \mathbf{Loglinear Model　}&\ln(Y)=\beta_1+\beta_2X_{2}+\epsilon\\
  \mathbf{Linearlog Model　}&Y=\beta_1+\beta_2\ln(X_{2})+\epsilon\\
  \mathbf{Loglog Model　}&\ln(Y)=\beta_1+\beta_2\ln(X_{2})+\epsilon
\end{align}
$(5) \sim (7)$式については良く知られた通り, 対数を取っている部分は変化率を示している.
\begin{align}
  \mathbf{Dummy Variable　}&Y=\beta_1+\beta_2X_{2}+\beta_3D+\epsilon\\
  \mathbf{Interaction Term　}&Y=\beta_1+\beta_2X_{2}+\beta_3X_{2}D+\epsilon\\
  \mathbf{Dummy+Interaction　}&Y=\beta_1+\beta_2X_{2}+\beta_3D+\beta_4X_{2}D+\epsilon
\end{align}
(8)は切片に, (9)は傾きにダミーの影響を加えるモデルで, 両者を合わせたのが(10)である. 次に\rmfamily\mcfamily\bfseries{多項回帰モデル (polynomial regression model)}\mdseries  $ y_i = \beta_1 + \beta_2 x_{i,2} + \beta_3 x_{i,2}^2 + \dots + \beta_r x_{i,2}^{r-1} + \epsilon_i$ を考える. このモデルの関数形決定では$t$検定で$r$の値を決定し, その後に帰無仮説$H_0 : \beta_3 = 0, \dots, \beta_r = 0$に基づく$F$検定を行う. これは逐次仮説検定 (sequential hypothesis testing)と呼ばれる.\\

\section{不均一分散}
仮定を弱めた\rmfamily\mcfamily\bfseries{一般化回帰モデル}\mdseries について考える. 先述の通り, 推定量の不偏性は保たれるが, 標準誤差が\rmfamily\mcfamily\bfseries{望ましい有意水準の信頼区間を生成しない}\mdseries 点で内的妥当性に打撃が与えられる. 解決法としてはGLSEによる推定と, 頑健標準誤差の利用がある. 一般化回帰モデルの仮定は以下の通り.
\begin{align*}
  &\mathbf{(GLS1)}　\mathbb{E}(\epsilon|\mathbf{X})=\mathbf{0}\\
  &\mathbf{(GLS2)}　\mathbf{Var}(\epsilon | \mathbf{X})=\mathbf{E}[\epsilon\epsilon^T| \mathbf{X}]=\sigma^2\Omega(\mathbf{X})=\sigma^2\Omega\\
  &\mathbf{(GLS3)}　(\mathbf{x}_{i}, \epsilon_{i})\text{は無限ではない4次のモーメントを持つ}\\
  &\mathbf{(GLS4)}　\text{フルランク(識別)}: rank(\mathbf{X})=K
\end{align*}
(GLS1)が(A1), (A2)のもとでも成り立つことは\rmfamily\mcfamily\bfseries{2.4}\mdseries で確認済み. 均一分散と正規性の仮定が外れていることを確認しよう. i.i.d.だが条件付不均一分散をもつデータと, 均一分散だが系列相関を持つデータにGLSは適応できるが, 今回は前者のケースに照準を合わせる. 先ず不偏性を確認しておこう. $\mathbf{b}=(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{X}^{T}\mathbf{Y}=\beta+(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{X}^{T}\epsilon$で, (GLS1)より$\mathbf{E}[\mathbf{b}|\mathbf{X}]=\beta+(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{X}^{T}\mathbf{E}[\epsilon|\mathbf{X}]=\beta$でLIEにより$\mathbf{E}[b]=\beta$を得た. また, 条件付分散は以下のようにかけて, 対称行列である.
\begin{equation*}
  Var(\epsilon|\mathbf{X})
  =\sigma^2
  \underset{\Omega}{\underbrace{
  \begin{pmatrix}
    \omega_{1}&\omega_{1,2}&\dots&\omega_{1,n}\\
    \omega_{2,1}&\omega_{2}\\
    &&\ddots\\
    &&&\omega_{n}
 \end{pmatrix}
  }}
 　with　\omega_{i,j}=\omega_{j,i}=\frac{Cov(\epsilon_i,\epsilon_j|\mathbf{X})}{\sigma^2}, \omega_i=\frac{Var(\epsilon_i|\mathbf{X})}{\sigma^2}
\end{equation*}
i.i.d.仮定(A2)の下では, \rmfamily\mcfamily\bfseries{2.4}\mdseries で見たように$\Omega$は対角行列.また, 均一分散(A5)の場合は対角成分が全て$1$. 再度仮定をGLSの標準的なものに緩め, 問題となるOLSEの分散を考える. $\mathbf{Var}[\mathbf{b}|\mathbf{X}]=\mathbf{E}[(\mathbf{b}-\beta)(\mathbf{b}-\beta)^T|\mathbf{X}]=\mathbf{E}[(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{X}^{T}\epsilon\epsilon^T\mathbf{X}(\mathbf{X}^{T}\mathbf{X})^{-1}|\mathbf{X}]=(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{X}^{T}\mathbf{E}[\epsilon\epsilon^T|\mathbf{X}]\mathbf{X}(\mathbf{X}^{T}\mathbf{X})^{-1}=\sigma^2(\mathbf{X}^{T}\mathbf{X})^{-1}(\mathbf{X}^{T}\Omega\mathbf{X})(\mathbf{X}^{T}\mathbf{X})^{-1}$. $\epsilon$の正規性を仮定すれば, $\mathbf{b}|\mathbf{X} \sim \mathcal{N}(\beta, \sigma^2(\mathbf{X}^{T}\mathbf{X})^{-1}(\mathbf{X}^{T}\Omega\mathbf{X})(\mathbf{X}^{T}\mathbf{X})^{-1})$. 最早今までの$s^2(\mathbf{X}^{T}\mathbf{X})^{-1}$に基づく議論は無意味. 更に古典的仮定に基づくガウスマルコフの定理は不成立でBULEでもない. 再度推定量のBULE化を目指すのが一般最小二乗法(Generalized Least Squares), 正確な標準誤差導出を目指すのが頑健標準誤差(Robust standard errors).\\

\subsection{一般最小二乗法}
上記の問題は(A5)の破れから発生するため, これを再び満足する変換を施す. $\Omega$が既知とすると, $\Omega^{-1}=P^{T}P$となる正則行列$P$が存在することが示せる. 次に, 回帰方程式に$P$を掛け, $P\mathbf{Y} = P\mathbf{X}β + P\epsilon$を得る. これを$\mathbf{Y}_\star = \mathbf{X}_\starβ + \epsilon_\star$に書き換える. $\epsilon_\star$の条件付き分散は以下の通り. $\mathbf{Var}[\epsilon_\star|\mathbf{X}_\star] = \mathbf{E}[\epsilon_\star\epsilon_\star^{T}|\mathbf{X}_\star] = \mathbf{E}[P\epsilon \epsilon^{T}P^{T}|\mathbf{X}_\star] = P\mathbf{E}[\epsilon \epsilon^{T}|\mathbf{X}_\star]P^{T} =\sigma^2P\Omega P^{T} = \sigma^2\mathbf{I}$. (A5)が変換後のモデルに再び適用される. 変換後のモデルに従い計算した以下が一般最小二乗推定量.
\begin{equation*}
  \mathbf{b}_\star=(\mathbf{X}_\star^{T}\mathbf{X}_\star)^{-1}\mathbf{X}_\star^{T}\mathbf{Y}_\star=(\mathbf{X}^{T}\Omega^{-1}\mathbf{X})^{-1}\mathbf{X}^{T}\Omega^{-1}\mathbf{Y}
\end{equation*}
(A5)を満たすため, GLSEの$\mathbf{b}_\star$は再度BULEとなった. 条件付分布は, $\mathbf{b}_\star|\mathbf{X}_\star \sim \mathcal{N}(\beta, \sigma^2(\mathbf{X}_\star^{T}\mathbf{X}_\star)^{-1})$. ここで, $\mathbf{Var}[\mathbf{b}_\star|\mathbf{X}_\star] = \sigma^2(\mathbf{X}_\star^{T}\mathbf{X}_\star)^{-1} = \sigma^2(\mathbf{X}^{T}\Omega^{-1}\mathbf{X})^{-1}$. GLSEは$\Omega^{-1}$で重み付けした, OLSEのような推定量である. しかし, $\Omega$は一般的には\rmfamily\mcfamily\bfseries{観測不能}\mdseries . 不均一分散だが系列相関のない特別な場合を考えよう. この結果得られるのが\rmfamily\mcfamily\bfseries{加重最小二乗(Weighted Least Squares)推定量}\mdseries である. このとき,
\begin{align*}
  &\Omega = diag(\omega_1, \omega_2, \ldots, \omega_n),
  　\Omega^{-1} = P^{T}P = diag(\frac{1}{\omega_1}, \frac{1}{\omega_2}, \ldots, \frac{1}{\omega_n}), 
  　P = diag(\frac{1}{\sqrt{\omega_1}}, \frac{1}{\sqrt{\omega_2}}, \ldots, \frac{1}{\sqrt{\omega_n}})\\
  &\because　\mathbf{y}_\star = P\cdot \mathbf{y} = 
  \begin{pmatrix}
    \frac{y_1}{\sqrt{\omega_1}}\\
    \frac{y_2}{\sqrt{\omega_2}}\\
    \vdots\\
    \frac{y_n}{\sqrt{\omega_n}}
 \end{pmatrix},
 　\mathbf{X}_\star = P \mathbf{X} = 
  \begin{pmatrix}
    \frac{\mathbf{x}_1^T}{\sqrt{\omega_1}}\\
    \frac{\mathbf{x}_2^T}{\sqrt{\omega_2}}\\
    \vdots\\
    \frac{\mathbf{x}_n^T}{\sqrt{\omega_n}}
 \end{pmatrix},
 　\mathbf{b}_\star= (\sum_{i=1}^{n} \frac{1}{\omega_i}\mathbf{x}_i\mathbf{x}_i^T)^{-1} (\sum_{i=1}^{n}\frac{1}{\omega_i}\mathbf{x}_iy_i^T)
\end{align*}
WLSEを適用すると, 観測値への加重が大きくなるほど, 観測値の分散は小さくなる.\\

\rmfamily\mcfamily\bfseries{Ex. 時給に関する性差}\mdseries　時給を女性ダミーに回帰して$H_i = \beta_1 + \beta_2 F_i + \epsilon_i$を考える. $Var[\epsilon_i|F_i= 0] = E[(H_i - \beta_1)^2|F_i= 0] = Var[H_i |F_i= 0], Var[\epsilon_i|F_i= 1] = E[(H_i - \beta_1 - \beta_2)^2|F_i= 1] = Var[H_i |F_i = 1]$. ここで, 不均一分散$Var[\epsilon_i|F_i= 1] \neq Var[\epsilon_i|F_i= 0]$が認められたとしよう. この場合の適切な推定方法は?　\rmfamily\mcfamily\bfseries{解答}\mdseries　系列相関を考えなくて良いとして, WLSを利用する. $\omega_i$は$\frac{Var(\epsilon_i|F_i=0)}{\sigma^2}$か$\frac{Var(\epsilon_i|F_i=1)}{\sigma^2}$どちらかをとる. ここで, 観測不能な分散を推定量に置き換える必要があり, スカラー$\sigma^2$はすべての重みに共通するため比例関係に影響を与えず取り除く事が出来る. 結果, $\frac{H_i}{\sqrt{\hat{Var}(\epsilon_i|F_i)}}$を$\frac{1}{\sqrt{\hat{Var}(\epsilon_i|F_i)}}, \frac{F_i}{\sqrt{\hat{Var}(\epsilon_i|F_i)}}$に回帰することでWLSE$b_\star$を得る.\\

\subsection{頑健標準誤差}
標準誤差に問題があることが分かっているので, これを不均一分散のもとでも使える, すなわち頑健なものに置き換えることは自然な解決策の一つだろう. 簡単のため, ここでも系列相関のない不均一分散を考える. また, 大標本理論に基づく議論であるため, \rmfamily\mcfamily\bfseries{3.2}\mdseries での議論と同様(予定)にデータはi.i.d.かつ(A4a) $\mathbf{E}[\mathbf{x}_i\mathbf{x}_i^T] = Q$ はpositive definiteと仮定する. これは正則行列であることの十分条件であり, 正則行列であることは逆行列の存在を保証している. ここで, $\sqrt{n}(\mathbf{b}-\beta)=(\sum_{i=1}^{n} \frac{1}{n}\mathbf{x}_i\mathbf{x}_i^T)^{-1}\sqrt{n}(\sum_{i=1}^{n} \frac{1}{n}\mathbf{x}_i\epsilon_i)\overset{d}{\to} \mathcal{N}(\mathbf{0}, Q^{-1}\Sigma Q^{-1})$だった(?). 均一分散の下では, $\Sigma=\sigma^2\mathbf{E}[\mathbf{x}_i\mathbf{x}_i^T] = \sigma^2Q$(?). それゆえ, $\mathbf{ \text{AVar}[b]}=\frac{\sigma^2}{n}Q^{-1}$, $\hat{\mathbf{\text{AVar}}[\mathbf{b}]}=s^2(\mathbf{X}^T\mathbf{X})^{-1}$. 一方不均一分散の下では, $\Sigma=\mathbf{E}[\epsilon_i^2\mathbf{x}_i\mathbf{x}_i^T]$であり, $\mathbf{ \text{AVar}[b]}=\frac{1}{n}Q^{-1}\Sigma Q^{-1}$. 以前のように$Q$を$\frac{1}{n}\sum_{i=1}^{n} \mathbf{x}_i\mathbf{x}_i^T$で推定し, 同様に$\frac{1}{n-K}\sum_{i=1}^{n} e_i^2\mathbf{x}_i\mathbf{x}_i^T \overset{p}{\to} \Sigma$の(左辺)を一致推定量とする, ここで$e_i$は残差. $\hat{\mathbf{\text{AVar}}[\mathbf{b}]}=\frac{1}{n} (\frac{1}{n}\sum_{i=1}^{n} \mathbf{x}_i\mathbf{x}_i^T)^{-1} (\frac{1}{n-K}\sum_{i=1}^{n} e_i^2\mathbf{x}_i\mathbf{x}_i^T) (\frac{1}{n}\sum_{i=1}^{n} \mathbf{x}_i\mathbf{x}_i^T)^{-1}$. この頑健推定量は White (1980) によって提案されたもので, 不均一分散の状況に一般的に適応可能. 頑健標準誤差（White standard errors）とホワイトの不均一分散検定は以下の通り.
\begin{align*}
  &\mathbf{（White Standard Errors）}　se(b_k)=\sqrt{\hat{\mathbf{\text{AVar}}[\mathbf{b}]}_{k,k}}\\
  &\mathbf{（White'sTestforHeteroskedasticity）}　H_0: \sigma_i^2=\sigma^2 \forall i　vs.　H_1: not　H_0
\end{align*}

\rmfamily\mcfamily\bfseries{ホワイト検定の手順}\mdseries :　二乗残差$e_i^2$を$X^T X$の全ての上三角部分の成分に回帰する. この時検定統計量$nR^2$は漸近的に自由度$J-1$の$\chi^2$に従う. ここで$J$は定数を含む回帰変数の数.\\

頑健な標準誤差と検定統計量を計算できる場合, 通常の標準誤差を気にする必要はないのだろうか? 答えは標本サイズに左右される. 頑健検定統計量と信頼区間は, 漸近的な正当性しか持たない. そのため, 標本サイズが小さい場合, 頑健統計量は適切に動作するとは限らず, むしろ通常の統計量よりもバイアスが大きいこともある. ただ, 標本サイズが大きい場合には頑健統計量のみの報告で十分とする見方もある. 最後に, $K=2$のケースでの公式を求めてみよう. $\sqrt{n}({b}-\beta) \overset{d}{\to} \mathcal{N}({0}, Q^{-1}\Sigma Q^{-1}) = \mathcal{N}({0}, \frac{Var((X_{i,2}-\mu_{X_2})\epsilon_i)}{(Var(X_{i,2}))^2})$, $Var((X_{i,2}-\mu_{X_2})\epsilon_i)=\mathbb{E}[\epsilon_i^2(X_{i,2}-\mu_{X_2})^2]$. 均一分散の時は, $Var((X_{i,2}-\mu_{X_2})\epsilon_i)=\sigma^2 Var(X_2)$. 各部分の一致推定量を利用すれば, 不均一分散の時は$\hat{\mathbf{\text{AVar}}[b_2]}=\frac{1}{n}\frac{\frac{1}{n-2}\sum(X_{i,2}-\bar{X_2})^2\cdot e_i^2}{(\frac{1}{n}\sum(X_{i,2}-\bar{X_2})^2)^2} = \frac{1}{n}\frac{\frac{1}{n-2}\sum(X_{i,2}-\bar{X_2})^2\cdot e_i^2}{(s_{X_2}^2)^2}$, 均一分散の時は$\hat{\mathbf{\text{AVar}}[b_2]} = \frac{1}{n}\frac{s^2\cdot s_{X_2}^2}{(s_{X_2}^2)^2} = \frac{1}{n}\frac{s^2}{s_{X_2}^2}$である. これはもとのOLSで得られるものと同一.\\

\section{操作変数法}
説明変数が誤差項と相関する内生性の存在のもとでは(A1)が崩れ, 正確な因果推論を行えなくなる. 内生性を発生する要因としては, 先述の通り, 欠落変数, 測定誤差, 同時性などがあった. では, 一般に内生性がOLS推定に引き起こす影響とは? また, コントロール変数, 代理変数のデータ等が入手不可能な場合の解決策とは? ここで我々が導入するのが\rmfamily\mcfamily\bfseries{操作変数法（Instrumental Variable Method, IV Method）}\mdseries である. ここでは価格弾力性の推定を例に考えて, その後に一般的な操作変数の定義を行うこととする.\\

\rmfamily\mcfamily\bfseries{Ex. 需要の価格弾力性と部分均衡}\mdseries　喫煙による病気や死亡を減らすため, タバコに課税したい. タバコの消費量を$20$パーセント削減するには, タバコの販売価格をどのくらい引き上げる必要があるだろうか? これを知るためにタバコの需要の弾力性, つまり\rmfamily\mcfamily\bfseries{需要方程式}\mdseries の係数$\beta_1$を推定する:
\begin{equation*}
  \underset{q_i}{\underbrace{ln(Q_i)}} = \beta_0 + \beta_1 \underset{p_i}{\underbrace{ln(P_i)}} + \epsilon_i
\end{equation*}
今, 観測値 $(Q_i, P_i), i = 1,\dots,n$が得られたとする. OLS 推定は一致性を持つだろうか? 結論としては否, その理由を以下で追っていこう. 部分均衡理論に基づく構造方程式は以下のとおり.
\begin{align*}
  &\mathbf{Demand}:　q_i^D = \beta_0 + \underset{theoretically <0}{\underbrace{\beta_1}} p_i + \underset{Demand Slide}{\underbrace{\epsilon_i}}\\
  &\mathbf{Supply}:　　q_i^S = \alpha_0 + \underset{theoretically >0}{\underbrace{\alpha_1}} p_i + \underset{Supply Slide}{\underbrace{\nu_i}}
\end{align*}
各関数(構造方程式)の誤差項は独立$Cov(\epsilon_i, \nu_i)=0$と仮定する. 均衡価格は市場一掃条件を満たす価格水準として定義されるため, $q_i^S=q_i^D=q_i$であり, この均衡水準での数量と価格のデータ$(q_i, p_i)$が$n$個与えられていると考えられる. $q_i$を$p_i$に回帰したときのOLSEは$b_1^{OLS}=\frac{\hat{Cov}(p_i, q_i)}{\hat{Var}(p_i)} \overset{p}{\to} \beta_1 + \frac{{Cov}(p_i, \epsilon_i)}{{Var}(p_i)}$. 均衡点では$\beta_0 + \beta_1 p_i + \epsilon_i = \alpha_0 + \alpha_1 p_i + \nu_i$. 変形して, $p_i = \frac{\alpha_0 - \beta_0 + \nu_i}{\beta_1 - \alpha_1} - \frac{1}{\beta_1 - \alpha_1}\epsilon_i$ with $\beta_1 - \alpha_1 <0$. 今までの関係式を利用して, $Cov(p_i, \epsilon_i) = -\frac{1}{\beta_1 - \alpha_1}Var(\epsilon_i) > 0$を得る. $b_1^{OLS}$の確率極限が$\beta_1 + \frac{{Cov}(p_i, \epsilon_i)}{{Var}(p_i)} > \beta_1$となるため, OLSEは\rmfamily\mcfamily\bfseries{もはや一致推定量でない}\mdseries . ここで一致推定量を得る方法として挙がってくるのが\rmfamily\mcfamily\bfseries{操作変数}\mdseries の利用だ. 供給関数を以下のように書き換えよう.
\begin{equation*}
  \mathbf{SupplyModified}:　　q_i^S = \alpha_0 + \alpha_1 p_i + \underset{\nu_i}{\underbrace{\alpha_2 z_i + u_i}}
\end{equation*}
ここで, $z_i$は観測可能で$Cov(z_i, \epsilon_i) = 0$. つまり\rmfamily\mcfamily\bfseries{供給には影響を与えるが需要には影響を与えない変数}\mdseries である. $Cov(z_i, u_i) = 0, Cov(\epsilon_i, u_i) = 0$. 均衡では$p_i = \frac{\alpha_0 - \beta_0}{\beta_1 - \alpha_1} + \frac{\alpha_2}{\beta_1 - \alpha_1} z_i + \frac{u_i - \epsilon_i}{\beta_1 - \alpha_1}$から, $Cov(z_i, p_i) = \frac{\alpha_2}{\beta_1 - \alpha_1}Var(z_i) \neq 0$. 今までの関係式を利用して, $Cov(q_i, z_i) = Cov(\beta_0 + \beta_1 p_i + \epsilon_i, z_i) = \beta_1 Cov(p_i, z_i)$より, 変形して$\beta_1 = \frac{Cov(q_i, z_i)}{Cov(p_i, z_i)}$を得る. これを標本対応した $b_1^{IV} = \frac{s_{q,z}}{s_{p,z}}$が\rmfamily\mcfamily\bfseries{IV推定量}\mdseries である. この推定量は明らかに\rmfamily\mcfamily\bfseries{一致性を持つ}\mdseries . 均衡水準は需要, 供給関数両者の位置によって決定するもので, そのスライドを意味する各関数の誤差項の処理が十分でないことに起因する推定のズレが問題である. そのため, \rmfamily\mcfamily\bfseries{片方の関数の位置を固定し, もう片方の振る舞いを観測データ（均衡水準）から特定できるようにしたい}\mdseries 訳だが, 操作変数法はそれを実現するための手法なのだ.\\

\subsection{単回帰での操作変数}
では一般の操作変数法を議論しよう. 構造モデルが以下で与えられるとする.
\begin{equation*}
  y_i = \beta_0 + \beta_1 x_i + \epsilon_i　with　Cov(x_i, \epsilon_i) \neq 0
\end{equation*}
このとき, $b_1 \overset{p}{\to} \beta_1 + \frac{Cov(x_i, \epsilon_i)}{Var(x_i)}$で, $x_i$が誤差項と相関している, つまり\rmfamily\mcfamily\bfseries{内生変数}\mdseries だとする. このとき, (A1)が崩れるため一致推定量でなくなる. 操作変数法は$x_i$を$\epsilon_i$と相関する部分と無相関の部分に分解する. $\beta_1$を推定するために利用するのは\rmfamily\mcfamily\bfseries{無相関の部分のみ}\mdseries . では$x_i$を分解する方法は? $x_i$と相関するが誤差項とは無相関の操作変数を見つければよい. 先ほどの例からも分かる通り, 操作変数は直接的な因果効果を被説明変数に対して持っておらず(外生性), あくまで相関により, 構造モデルに入っている他説明変数の因果関係を媒介している(関連性)に過ぎないことを留意せよ. まとめると, 以下の性質が操作変数には望ましい.
\begin{align*}
  &1. 操作変数の関連性:　Corr(x_i , z_i ) \neq 0\\
  &2. 操作変数の外生性:　Corr(\epsilon_i , z_i ) = 0
\end{align*}
$x_i$は$z_i$に回帰することで, $x_i = \pi_0 + \pi_1 z_i + \nu_i ⇒ \hat{x_i} = \hat{\pi_0} + \hat{\pi_1} z_i$ と分解される（第1段階）. 次に$y_i$を$\hat{x_i}$に回帰する（第2段階）. これが\rmfamily\mcfamily\bfseries{二段階最小二乗法（TSLS）}\mdseries . TSLS推定量を$b_1^{TSLS}$で表す. この確率極限は$b_1^{TSLS} = \frac{s_{z,y}}{s_{z,x}} \overset{p}{\to} \frac{Cov(z_i, y_i)}{Cov(z_i, x_i)} = \beta_1$ で, 先述の例の通り一致性を持つ. 漸近分布は$b_1^{TSLS} \overset{a}{\sim} \mathcal{N}({\beta_1}, \sigma_{b_1^{TSLS}}^2)$ where $\sigma_{b_1^{TSLS}}^2 = \frac{1}{n}\frac{Var((z_i - \mu_z)\epsilon_i)}{[Cov(z_i, x_i)]^2}$. なお, 不均一分散のもとでも頑健である. この推定量の正統性を, 種々の仮定を置きながら確認してみよう.\\

\rmfamily\mcfamily\bfseries{Ex. $x$が外生変数（A1）, 均一分散（A5）}\mdseries　まず$x$が外生変数（A1）とする. つまり, OLSEは一致推定量. $z$が適切な操作変数ならばOLSEとIVEは整合する筈. $x$自体を操作変数として利用しよう. $b_1^{TSLS} = \frac{s_{z,y}}{s_{z,x}} = \frac{s_{x,y}}{s^{2}_{x}} = b_1^{OLS}$. $\sigma_{b_1^{TSLS}}^2 = \frac{1}{n}\frac{Var((z_i - \mu_z)\epsilon_i)}{[Cov(z_i, x_i)]^2} = \frac{1}{n}\frac{Var((z_i - \mu_z)\epsilon_i)}{[Var(x_i)]^2} = \sigma_{b_1^{OLS}}^2$. これは不均一分散（A5）のもとでのOLSEの漸近分散であり, この推定量の平方根がホワイトの頑健標準誤差である. さらに, もし$\mathbb{E}[\epsilon_i^2 | x_i] = \sigma^2$ならば, $Var((x_i - \mu_x)\epsilon_i) = \mathbb{E}[(x_i - \mu_x)^2\epsilon_i^2] \overset{LIE}{=} \mathbb{E}[(x_i - \mu_x)^2\mathbb{E}[\epsilon_i^2 | x_i]] = \sigma^2 Var(x_i)$であるので, $\sigma_{b_1^{OLS}}^2 = \frac{1}{n}\frac{\sigma^2}{Var(x_i)}$. この推定量は均一分散におけるOLSの標準誤差と整合.\\

\rmfamily\mcfamily\bfseries{Ex. 均一分散（A5）}\mdseries　$x$が内生変数とする. このとき一致性が崩れる. $z_i$が適切な操作変数とする. かつ均一分散を仮定しよう. 前の例と同様にして, TSLS推定量は以下のように計算できる.
\begin{equation*}
  \sigma_{b_1^{TSLS}}^2 = \frac{1}{n}\frac{\sigma^2Var(z_i)}{[Cov(z_i, x_i)]^2} = \underset{\sigma_{b_1^{OLS}}^2}{\underbrace{\frac{1}{n}\frac{\sigma^2}{Var(x)}}} \cdot \underset{\geq 1}{\underbrace{\frac{1}{\rho_{x, z}^2}}}
\end{equation*}
以上より(A5)では$\sigma_{b_1^{TSLS}}^2 = \frac{\sigma_{\epsilon}^2}{n \sigma_{x}^2}\frac{1}{\rho_{x, z}^2}$. 一方OLSは$\sigma_{b_1^{OLS}}^2 = \frac{\sigma_{\epsilon}^2}{n \sigma_{x}^2}$. 故に目安として, TSLSでの標準誤差はOLS標準誤差より約$\frac{1}{r_{x, z}^2}$大きくなる. ここで$r_{x,z}$は標本相関. この要因は, OLSを実行できる場合に\rmfamily\mcfamily\bfseries{TSLSを実行するコスト}\mdseries と解釈可能. なおOLSが使えない場合比較は無為. また, 操作変数が内生変数である可能性も考慮する必要がある. 確認のため確率極限を見てみよう.
\begin{align*}
  &b_1^{OLS} \overset{p}{\to} \beta_1 + \frac{\sigma_{\epsilon}}{\sigma_{x}} \cdot Corr(x, \epsilon)\\
  &b_1^{TSLS} = \beta_1 + \frac{s_{z,y}}{s_{z,x}} \overset{p}{\to} \beta_1 + \frac{\sigma_{\epsilon}}{\sigma_{x}} \cdot \frac{Corr(z, \epsilon)}{Corr(z, x)}
\end{align*}
ここでTSLSのバイアスは$Corr(z, x)$で大幅に増幅される. 実際$.10$以下になる事もままある.\\

\rmfamily\mcfamily\bfseries{Ex. タバコ需要の価格弾力性}\mdseries　1995年の米国本土48州のクロスセクションデータを使用する. $Q_i$: 州内で1人あたりに販売されたタバコの箱数, $P_i$: すべての税金を含むタバコ1箱あたりの平均実質価格, である. 価格の操作変数として一般消費税を使用する. TSLS推定の結果は以下.
\begin{align*}
  \hat{ln(Price_i)} &= \underset{(0.03)}{4.63}  + \underset{(0.005)}{0.031}  SalesTax_i\\
  \hat{ln(Q_i)} &= \underset{(1.53)}{9.72} - \underset{(0.32)}{1.08}  ln(P_i)
\end{align*}
以上より需要の価格弾力性が$-1.08$と推定された. この結果の有効性は?　\rmfamily\mcfamily\bfseries{解答}\mdseries　一段階目の$t$値は約$6$で凡その水準で統計的有意. 二段階目にも有意性を認められるため, 有効であろう.\\

\subsection{一般操作変数モデル}
より一般的な回帰モデルについて操作変数法を使おう. 以下の回帰モデルを考える.
\begin{equation*}
  y_i = \beta_0 + \beta_1 x_{i,1} + \dots + \beta_K x_{i,K} + \beta_{K+1} w_{i,1} + \dots + \beta_{K+r} w_{i,r} + \epsilon_i
\end{equation*}
ここで, $x_{i,1}, \dots, x_{i,K}$ : $K$個の内生回帰変数 ($\epsilon_i$と相関) , $w_{i,1}, \dots, w_{i,r}$ : $r$個の外生回帰変数 ($\epsilon_i$と無相関)若しくはコントロール変数. $z_{i,1}, \dots, z_{i,m}$ : $m$個の操作変数. 内生回帰変数よりも操作変数の数が多い場合 $(m > K)$, 係数は\rmfamily\mcfamily\bfseries{過剰識別（overidentification）}\mdseries される. $m < K$の場合は\rmfamily\mcfamily\bfseries{過少識別（underidentification）}\mdseries され, $m = K$の場合は\rmfamily\mcfamily\bfseries{丁度識別（just identification）}\mdseries される. IV回帰モデルの推定には, \rmfamily\mcfamily\bfseries{丁度識別または過剰識別}\mdseries が必要. さもなければ解は無限個存在する, 連立方程式の解についての性質からも分かるだろう. ではTSLSについて考えよう.\\

\rmfamily\mcfamily\bfseries{第一段階}\mdseries :　$K$個の各内生回帰変数を$m$個の操作変数と$r$個の外生回帰変数に回帰する.
\begin{equation*}
  x_{i,k} = \pi_{0,k} + \pi_{1,k}z_{i,1} + \dots + \pi_{m,k}z_{i,m} + \pi_{m+1,k}w_{i,1} + \dots + \pi_{m+r,k}w_{i,r} + \nu_{i,k}
\end{equation*}
結果, 予測値 $\hat{x_{1,k}}, \dots, \hat{x_{n,k}}$ が各内生回帰変数に対して得られる.\\

\rmfamily\mcfamily\bfseries{第二段階}\mdseries :　$y_i$を$\hat{x_{i,1}}, \dots, \hat{x_{i,K}}, w_{i,1}, \dots, w_{i,r}$に回帰し$\mathbf{b}^{TSLS} = (b_0^{TSLS}, \dots, b_{K+r}^{TSLS})^T$を得る.\\

操作変数の\rmfamily\mcfamily\bfseries{関連性と外生性}\mdseries を, 一般の場合にはどのように定義すべきだろうか. $m$個の操作変数集合$z_{i,1}, \dots, z_{i,m}$が有効であるためには, 次の$2$条件を満たす必要がある:\\

\rmfamily\mcfamily\bfseries{1. 関連性}\mdseries :　$(1, \hat{x_{i,1}}, \dots, \hat{x_{i,K}}, w_{i,1}, \dots, w_{i,r})$は完全な多重共線性を持たない (操作変数は, $x_{i,k}$の外生的部分$\hat{x}_{i,k}$に関する十分な情報を, これらの$y_i$に対する個別の影響を整理するために, 提供する必要がある. $K = 1$の場合, これは少なくとも$1$つの操作変数が第一段階回帰で関連している必要があることを意味する. 単回帰の例に一致していることを確認せよ.(要検討))

\rmfamily\mcfamily\bfseries{2. 外生性}\mdseries :　$Corr(z_{i,1}, \epsilon_i) = 0, \dots, Corr(z_{i,m}, \epsilon_i) = 0$ (各説明変数は誤差項と無相関)\\

更に, 次のIV回帰仮定が満たされれば, TSLS推定量は大標本で一致性があり, 正規分布に従う:
\begin{align*}
  &\mathbf{(IV1)}　\mathbb{E}(\epsilon_i|w_{i,1}, \dots, w_{i,r})=0　\mathbf{or}　\mathbb{E}(\epsilon_i|z_{i,1}, \dots, z_{i,m}, w_{i,1}, \dots, w_{i,r}) = \mathbb{E}(\epsilon_i|w_{i,1}, \dots, w_{i,r})\\
  &\mathbf{(IV2)}　(x_{i,1}, \dots, x_{i,K}, w_{i,1}, \dots, w_{i,r}, z_{i,1}, \dots, z_{i,m}, y_i) \text{はそれらの同時分布からi.i.d.抽出される}\\
  &\mathbf{(IV3)}　\text{全ての変数は無限ではない4次のモーメントを持つ(外れ値が少ない)}\\
  &\mathbf{(IV4)}　\text{関連性と外生性が満たされる}
\end{align*}

\rmfamily\mcfamily\bfseries{Ex. タバコ需要の価格弾力性（Cont.）}\mdseries　先ほど操作変数として用いた消費税は外生的でない可能性がある. 例えば, 所得はタバコ需要に影響を与える可能性があり, 州の売上税と州の所得は相関している可能性がある. これは, 価格と数量の図上での需要供給曲線の動きを考えれば直感的だろう. 供給曲線が課税により上シフトする. ここで課税が適切な操作変数ならば需要曲線には影響を与えないはずだが, 内生性を持つならば需要曲線も同時に所得効果を通じて変動する筈だ. このため, 需要弾力性は所得をコントロールしなければ正確に予測できない筈である. 所得を外生コントロール変数として含め, 消費税を操作変数に使用した結果は次の通り.
\begin{equation*}
  \hat{ln(Q_i)} = \underset{(1.26)}{9.43} - \underset{(0.37)}{1.14}  ln(P_i) + \underset{(0.31)}{0.21}  ln(income_i)
\end{equation*}
タバコ税も操作変数として考えられる. 両変数を使用したTSLSでは次の通り.
\begin{equation*}
  \hat{ln(Q_i)} = \underset{(0.96)}{9.89} - \underset{(0.25)}{1.28}  ln(P_i) + \underset{(0.25)}{0.28}  ln(income_i)
\end{equation*}
$1$内生説明変数, $1$コントロール変数, $1 \sim 2$操作変数を有するモデル. $\rho_{tax, income} \approx .17 > 0$から, 税金が高い州程所得が高く, 所得をコントロールしなければ, 需要曲線は税率が上がる程上方に位置して, 正の所得効果が弾力性を相殺することが分かる（図を書けば分かる）. 所得をコントロールしない場合の価格弾力性の推定値$1.08 (< 1.14, 1.28)$は, 上記の過少推定の議論に整合的.\\

\subsection{操作変数の正統性に関する検定}
\subsubsection{関連性}
直感として, $x_{i,k}$の変動が操作変数で説明できるほど, TSLS推定量はより正確になる. 関連性は標本サイズと同様に, 大きいほど推定の精度を高めることが分かる. 単回帰の推定量の分散公式にも整合的な解釈である. $Corr(z_i , x_i)$が低すぎる場合, TSLS推定量にはバイアスがあり, 正規分布に従わなくなる. 極端な場合, $Corr(z_i , x_i) = 0$で, 操作変数は無関連と呼ばれる. ではどの程度の関連性が操作変数には必要なのだろうか? $(\mathbb{E}[b_1^{TSLS}] - \beta_1)/(\beta_1^{OLS} - \beta_1) \approx 1/(\mathbb{E}[F] - 1)$ ここで, $\beta_1^{OLS}$はOLS推定量の確率極限であり, $E(F)$ は, 第一段階の回帰で操作変数$z_{i,1}, \dots, z_{i,m}$の係数がゼロになるという帰無仮説の$F$統計量の期待値. この近似式より次の経験則を得る.\\

\rmfamily\mcfamily\bfseries{単一の内生的回帰変数の場合の経験則}\mdseries :　$F = 10$の場合, OLSのバイアスに対するTSLSのバイアスは約$1/9$. つまり$10$パーセントを僅かに超える. これを踏まえ, $F \geq 10$の時TSLSのバイアスは十分小さいとして慣習的に許容する. 逆に$F$統計量が$10$未満の場合は\rmfamily\mcfamily\bfseries{弱操作変数}\mdseries と呼ばれる.\\

\subsubsection{外生性}
操作変数の外生性がTSLS推定量の\rmfamily\mcfamily\bfseries{一致性}\mdseries を保証するのを想起せよ. 外生性は係数が過剰識別の場合にのみ検定可能である. 直感としては, 過剰識別の場合, 変数の選び取り方によって, 複数の係数推定値を作成できることによる. さらに, 全操作変数が外生の場合, 推定量は操作変数集合の取り方によるブレは少ない筈だ.\\

\rmfamily\mcfamily\bfseries{過剰識別制約テスト ($J$ 統計量)}\mdseries :　真の$x_{i,k}$を使用して, 二段階目回帰から残差を計算しする: $\hat{\epsilon}_i^{TSLS} = y_i - (b_0^{TSLS} + b_1^{TSLS} x_{i,1} + \dots + b_{K+r}^{TSLS} w_{i,r})$
次に, 操作変数と外生回帰変数へ, $\hat{\epsilon}_i^{TSLS}$ を回帰する. ここで, \rmfamily\mcfamily\bfseries{均一分散用の}\mdseries $F$統計量を使用して, 操作変数の係数がゼロであるという仮説の検定を行う. 大標本の場合 $J = mF \sim \chi^2(m - K)$. 制約と$F$検定の章を参照. 正規性を外した場合の値の漸近分布が$\chi^2$だったことを利用している(不正確, 確認の必要あり).\\

\rmfamily\mcfamily\bfseries{Ex. タバコ需要の価格弾力性（Cont.）}\mdseries　所得に加えて, タバコの消費に影響を与える他の変数を考える. これらの変数が州によって異なるが, 時間の経過とともに変化しない場合, \rmfamily\mcfamily\bfseries{パネルデータ}\mdseries を使用してDifference Estimationを実行可能. ここでは$1985$年と$1995$年のデータを使用し, 長期的な弾力性を推定.　\rmfamily\mcfamily\bfseries{結果の要約}\mdseries　 : 各回帰で $F$ 統計量が $10$ を超えており, 関連性は満たされている. ただし, 推定弾力性は操作変数の選択によって異なる. $J$検定: 両操作変数が外生的との仮説を棄却する. タバコ税はその外部性より, 内生的である可能性がある.\\

\subsection{一般TSLS推定量}
最後に, 一般の重回帰モデルでの操作変数法における, TSLS推定量の行列表記やその性質について考えよう. 記法:　$\mathbf{X}$は内生, 外生回帰変数を全てまとめた$n \times (K + r + 1)$行列. $i$行は$\mathbf{x}_i^T = (1, x_{i,1}, \dots, x_{i,K}, w_{i,1}, \dots, w_{i,r})$である. $\mathbf{Z}$は操作変数とモデルに含まれる外生変数を合わせた外生変数行列$n \times (m + r + 1)$行列. $i$行は$\mathbf{z}_i^T = (1, z_{i,1}, \dots, z_{i,m}, w_{i,1}, \dots, w_{i,r})$である. 以上の記法を用いて, IV回帰モデルは以下のように表記可能である.
\begin{equation*}
  \mathbf{y} = \mathbf{X}\beta + \epsilon　\mathbf{with}　\mathbf{E}[\mathbf{z}_i\epsilon_i] = \mathbf{0}
\end{equation*}
TSLS推定の一段階目では, 予測値行列$\hat{\mathbf{X}}$を求める. ここで, $\hat{\mathbf{x}}_i^T = (1, \hat{x}_{i,1}, \dots, \hat{x}_{i,K}, w_{i,1}, \dots, w_{i,r})$. 予測値は\rmfamily\mcfamily\bfseries{射影行列}\mdseries $\mathbf{P_Z}$を利用して次のように表記できる(=線形射影としてのOLS). 
\begin{equation*}
  \hat{\mathbf{X}} = \mathbf{P_Z}{\mathbf{X}} = \mathbf{Z}(\mathbf{Z}^T\mathbf{Z})^{-1}\mathbf{Z}^T\mathbf{X}
\end{equation*}
これらの記法を用いて, 二段階目は以下のように表記可能である.
\begin{equation*}
  \mathbf{b}^{TSLS} = (\hat{\mathbf{X}}^T\hat{\mathbf{X}})^{-1}\hat{\mathbf{X}}^T\mathbf{y} = (\mathbf{X}^T\mathbf{P_Z}{\mathbf{X}})^{-1}\mathbf{X}^T\mathbf{P_Z}\mathbf{y} = (\mathbf{X}^T\mathbf{Z}(\mathbf{Z}^T\mathbf{Z})^{-1}\mathbf{Z}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{Z}(\mathbf{Z}^T\mathbf{Z})^{-1}\mathbf{Z}^T\mathbf{y}
\end{equation*}
計算では$\mathbf{P_Z}$が対称行列であることを利用. 次に漸近分布を考える. モデルの定義と推定量より, 
\begin{equation*}
  \sqrt{n}(\mathbf{b}^{TSLS} - \beta) = (\frac{\mathbf{X}^T\mathbf{Z}}{n} (\frac{\mathbf{Z}^T\mathbf{Z}}{n})^{-1} \frac{\mathbf{Z}^T\mathbf{X}}{n})^{-1} \frac{\mathbf{X}^T\mathbf{Z}}{n} (\frac{\mathbf{Z}^T\mathbf{Z}}{n})^{-1} \frac{\mathbf{Z}^T\epsilon}{\sqrt{n}}
\end{equation*}
と書き換えが可能. 更にLLNとCLNより以下を得る.
\begin{equation*}
  \sqrt{n}(\mathbf{b}^{TSLS} - \beta) \overset{d}{\to} \mathcal{N}(\mathbf{0}, \Sigma^{TSLS})
\end{equation*}
条件付均一分散$\mathbf{E}[\epsilon_i^2|\mathbf{z}_i] = \sigma^2$の場合, 共分散行列は$\Sigma^{TSLS} = \sigma^2(\mathbf{E}[\mathbf{x}_i\mathbf{z}_i^T] (\mathbf{E}[\mathbf{z}_i\mathbf{z}_i^T])^{-1} \mathbf{E}[\mathbf{z}_i\mathbf{x}_i^T])^{-1}$. この場合TSLS推定量は, $\mathbf{Z}$の線形結合である操作変数を用いた推定量の中では漸近的に最良となる. 不均一分散の下では頑健標準誤差を利用して漸近分布を得ることが出来る.\\

\section{パネルデータ分析}
$n$エンティティを一度だけ観測する(=横断面データ)のではなく, $T$期間にわたってそれぞれの観測を繰り返すのがパネルデータである. ここで, 観測データは$(\mathbf{x}_{i,t}, y_{i,t}) = ((x_{i,t,1}, \dots, x_{i,t,K})^T, y_{i,t})$, $i=1,\dots,n$ and $t=1,\dots,T$のように与えられる. パネルデータ分析は, 幾つかの種類の欠落変数に対する有効なコントロールの手法として機能する. 例えば, $y_{i,t} = \mathbf{x}_{i,t}^T \beta + \mathbf{z}_{i}^T \alpha + \epsilon_{i,t}$のモデルを考えてみよう. ここで, $\mathbf{x}_{i,t}$は$K$個の時間で変動する回帰変数ベクトル, $\mathbf{z}_{i}$は定数項と, データ個別の時間不変の属性を表す変数を合わせた$2\times1$ベクトルである. この$\beta$の推定を目標に議論を進めよう.\\

\rmfamily\mcfamily\bfseries{Ex. 飲酒と交通事故死}\mdseries　横断面データにおける欠落変数バイアスの問題についての復習と, 如何にしてパネルデータ分析がその問題を解決するのかについて見るために, 一つの具体例を中心として話を進めよう. 交通事故死割合, ビール税, 飲酒運転の法制に関連する変数を, 米国の$n = 48$州に対して$1982 \sim 1988$ 年の$T = 7$年間に渡って調査した, 漏れの無い, つまり\rmfamily\mcfamily\bfseries{バランスした}\mdseries パネルデータを持っているとする. ここで, 総観測データ数は$nT = 336$. 飲酒運転を厳罰化する法制度設計は, 交通事故死を減少するのにどれほど効果的だろうか? 手始めに横断面データ分析の手法を取ってみよう. ビール税を説明変数とすればモデルは以下のように具体化される.
\begin{equation*}
  FatalityRate_{i,t} = \alpha_1 + \beta_1 BeerTax_{i,t} + \underset{Cross-sectional Error}{\underbrace{\alpha_2z_{i,2} + \epsilon_{i,t}}}
\end{equation*}
今までと同様に, $\alpha_2 \neq 0$ and $Cov(X_{i,t,1}, z_{i,2}) \neq 0$の時に欠落変数バイアスが存在し, OLS推定量は一致性を失う. たとえば, 欠落変数として交通量などが考えられる. 交通量が多ければ交通事故死は増え($\alpha_2 > 0$), 交通量が少ない州ではアルコール税が低い傾向にある($Cov(X_{i,t,1}, z_{i,2}) > 0$)と仮定すれば, 正の方向に欠落変数バイアスが働くだろう. 欠落変数をコントロールの為直接モデルに追加可能ならば問題は解決するが, 先述の通りしばしばこれは観測不可能である. ここで効力を発揮するのがパネルデータ分析である. 簡単のために, $1982, 1988$年の$T = 2$期間の場合から考えよう. モデルにおいて, $\mathbf{z}_{i} = (1, z_{i,2})^T$は定数項と, 州個別の時間不変の属性を表す変数を合わせた$2\times1$ベクトルである. $z_{i,2}$が時間を通じ一定との仮定より, 以下を得る.
\begin{equation*}
  FatalityRate_{i,1988} - FatalityRate_{i,1982} = \beta_1 (BeerTax_{i,1988} - BeerTax_{i,1982}) + \epsilon_{i,1988} - \epsilon_{i,1982}
\end{equation*}
差分同士での回帰を行うことで, 欠落変数バイアスを取り除いた推定が可能であることが分かった. この方法での推定を一般には, \rmfamily\mcfamily\bfseries{First Difference Estimation}\mdseries と呼ぶ.\\

\subsection{固定効果モデル}
First Difference Estimationは一般$T$期間には適応不可. そこで我々が次に検討するのが\rmfamily\mcfamily\bfseries{固定効果回帰(Fixed Effects Regression)}\mdseries . 再度$K = 1$で欠落変数が存在すると考え変形する.
\begin{equation*}
  y_{i,t} = \beta_1 {x}_{i,t,1} + \alpha_1 + \alpha_2 z_{i,2} + \epsilon_{i,t} = \beta_1 {x}_{i,t,1} + c_i + \epsilon_{i,t}
\end{equation*} 
全てのエンティティが同じ傾きを持つが, $\mathbf{z}_i$を纏めた切片が異なることが分かるだろう. ここでの$c_i$が固定効果(fixed effect)であり, 欠落変数, それに起因する個体間での時間不変の観測不能な異質性をコントロールする役割をはたしている. $\beta$の推定方法としては, \rmfamily\mcfamily\bfseries{1. ダミー変数の利用}\mdseries , \rmfamily\mcfamily\bfseries{2. 固定効果推定量(FE推定量)の利用}\mdseries , が考えられる. 先ず前者を検討しよう. 
\begin{equation*}
  y_{i,t} = \beta_1 x_{i,t,1} + c_1 + \gamma_2 D_{2,i} + \gamma_3 D_{3,i} + \dots + \gamma_n D_{n,i} + \epsilon_{i,t},　(D_{m,i} = 1　if　i=m,　0　else)
\end{equation*}
ゆえに, $c_i = c_1 + \gamma_i$ for $i \geq 2$. ダミー変数の罠を回避するため, この変数は$n-1$個. これで, モデルをOLSで推定できるようになった. 統計的推測は頑健標準誤差を用いた一般的なものを利用可能(不均一分散に頑健). しかし, $K + n$の係数を推定する必要があるため, これは$n$が非常に大きい場合は非現実的. 我々は$\beta$の推定にのみ興味があり, $c_i$を正確に推定する必要はない. このことを念頭において後者の\rmfamily\mcfamily\bfseries{FE推定量}\mdseries について考える. 簡単のため, 依然$K = 1$を考える. 時系列に標本平均をとって, $\bar{y}_i = \beta_1 \bar{x}_{i,1} + c_i + \bar{\epsilon}_i$. 辺々引いて以下を得る. 
\begin{equation*}
  y_{i,t} - \bar{y}_i = \beta_1 ({x}_{i,t,1} - \bar{x}_{i,1}) + (\epsilon_{i,t} - \bar{\epsilon}_i)
\end{equation*}
以上の式より, 偏差同士で回帰することでFE推定量(グループ内推定量, within estimator)とwithin R squaredを得る. $c_i$の項が相殺されている, 即ち固定効果がコントロールされていることに注目しよう. 標本平均でOLSを行った場合はbetween estimator(BE推定法)と呼ばれる. FE推定法での固定効果の推定量は$\hat{c}_i = \bar{y}_i - \bar{\mathbf{x}}_{i}^T \mathbf{b}_1^{FE}$で一般に得られる. 次に, \rmfamily\mcfamily\bfseries{時間固定効果回帰}\mdseries を見てみよう. 時間によって変化するが, 個人間で同一の効果をもたらす欠落変数も存在するだろう. 自動車事故死の例に当てはめるならば国家での法改正や, 車の安全性の向上などが例として挙げられる. 一般に, $n - 1$のエンティティダミーと, $T - 1$の期間ダミーを利用することで, $y_{i,t} = \beta_1 x_{i,t,1} + c_1 + \gamma_2 D_{2,i} + \gamma_3 D_{3,i} + \dots + \gamma_n D_{n,i} + \delta_2 B_{2,t} + \delta_3 B_{3,t} + \dots + \delta_T D_{T,t}+ \epsilon_{i,t}$のようにモデルを書き換えられる. OLSは$K + (n - 1) + (T - 1) + 1$個の係数を, FE推定量と同じく偏差同士で回帰することで推定可能.\\

\subsection{固定効果モデルの仮定}
簡単のため$K = 1$のケースを考える.
\begin{equation*}
  y_{i,t} = \beta_1 {x}_{i,t,1} + c_i + \epsilon_{i,t}
\end{equation*}
この固定効果モデルの条件は以下の通り.
\begin{align*}
  &\mathbf{(FE1)}　\mathbb{E}(\epsilon_{i,t}|x_{i,1,1}, x_{i,2,1}, \dots, x_{i,T,1}, c_i)=0\\
  &\mathbf{(FE2)}　(x_{i,1,1}, \dots, x_{i,T,1}, \epsilon_{i,1}, \dots, \epsilon_{i,T}) \text{はそれらの同時分布からi.i.d.抽出される}\\
  &\mathbf{(FE3)}　(x_{i,t,1}, \epsilon_{i,t})\text{は無限ではない4次のモーメントを持つ}\\
  &\mathbf{(FE4)}　\text{それぞれの説明変数は時間によって変動し, 完全な多重共線性はない} (K > 1の場合)
\end{align*}
(FE1)は強い外生性を意味しており, FE推定量が不偏性を持つことを保証している. 実際, この仮定から$Cov(\epsilon_{i,t}, x_{i,\tau,1}) = 0, \forall\tau\in\{1,\dots,T\}$も確認できる. (FE2)は誤差項の異なるエンティティ間での独立性を意味するものの, 同一エンティティ内では相関することがあり, この場合系列相関が存在しうる. また, 条件付の不均一分散も否定されていない. (FE1)\sim(FE4)の下で, $b_1^{FE}$の漸近分布は以下のように与えられる.
\begin{align*}
  &\sqrt{nT}(b_1^{FE} - \beta_1) \overset{a}{\sim} \mathcal{N}({0}, \frac{\sigma_\eta^2}{Q_{\tilde{x}}^2})\\
  &where　\eta_i = \frac{1}{\sqrt{T}}\sum_{t=1}^{T}\tilde{v}_{i,t},　\sigma_\eta^2 = Var[\eta]　and　Q_{\tilde{x}} = \mathbb{E}[\frac{1}{T}\sum_{t=1}^{T}\tilde{x}_{i,t,1}^2]\\
  &with　\tilde{v}_{i,t} = \tilde{x}_{i,t,1} \epsilon_{i,t}　and　\tilde{x}_{i,t,1} = {x}_{i,t,1} - \bar{x}_{i,t,1}
\end{align*}
$\sigma_\eta^2$の推定量として, 以下のクラスター化標準誤差(Clustered standard errors)が与えられる.
\begin{equation*}
  \hat{\sigma}_{\eta, cluster}^2 = \frac{1}{nT} \sum_{i=1}^{n} (\sum_{t=1}^{T}\hat{\tilde{v}}_{i,t})^2　where　\hat{\tilde{v}}_{i,t} = \tilde{x}_{i,t,1} e_{i,t}
\end{equation*}
$e_{i,t}$はFE推定におけるOLSの残差である. この推定量は$\epsilon_{i,t}$のエンティティ間における, 条件付不均一分散と条件付系列相関を制御している.\\

\subsection{一般のパネルデータ分析モデル}
パネルデータは例えば, 以下のように特定化できる.
\begin{equation*}
 y_{i,t} = \mathbf{x}_{i,t}^T \beta + \mathbf{z}_{i}^T \alpha + \epsilon_{i,t} = \mathbf{x}_{i,t}^T \beta + c_i + \epsilon_{i,t}
\end{equation*}
ここで, $c_i$は観測不能な異質性を表す. 我々は状況を以下の三つに大別することが出来る. 1. $\mathbf{z}_i$は完全に一定. 2. $\mathbf{z}_i$は$\mathbf{x}_{i,t}$と無相関. 3. $\mathbf{z}_i$は$\mathbf{x}_{i,t}$と相関. $1$の場合, プール回帰モデルは一致性を持ち, かつ最良推定量を導く. しかし$2$の場合, プール回帰の効率性は損なわれ, 解決法としてRE推定量の使用が挙げられる. さらに$3$の場合には不偏性も一致性も損なわれ, この解決法がFE推定量の使用である. 以下ではそれぞれの回帰モデルとその性質を確認してみよう.\\

\subsubsection{プール回帰モデル}
$\mathbf{z}_{i} = 1$で一定. 地点と個人を平等に扱い, 各被説明変数を$nT$個のデータを用いて回帰する. 
\begin{equation*}
  y_{i,t} = \alpha + \mathbf{x}_{i,t}^T \beta + \epsilon_{i,t}
\end{equation*}
\begin{align*}
  &\mathbf{(PL1)}　\mathbb{E}[\epsilon_{i,t}|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}]=0\\
  &\mathbf{(PL2)}　(\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}, \epsilon_{i,1}, \dots, \epsilon_{i,T}) \forall i\text{はそれらの同時分布からi.i.d.抽出される}\\
  &\mathbf{(PL3)}　(\mathbf{x}_{i,t}, \epsilon_{i,t})\text{は無限ではない4次のモーメントを持つ}\\
  &\mathbf{(PL4)}　\text{完全な多重共線性が存在しない}\\
  &\mathbf{(PL5)}　Var(\epsilon_{i,t}|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}) = \sigma_\epsilon^2\\
  &\mathbf{(PL6)}　Cov(\epsilon_{i,t}\epsilon_{i,s}|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}) = 0　\text{for}　t \neq s
\end{align*}
プールOLS推定量は以下で与えられる.
\begin{align*}
  &\mathbf{b}^{POLS} = (\sum_{i=1}^{n}\sum_{i=1}^{T}(\mathbf{x}_{i,t} - \bar{\bar{\mathbf{x}}})(\mathbf{x}_{i,t} - \bar{\bar{\mathbf{x}}})^T)^{-1} (\sum_{i=1}^{n}\sum_{i=1}^{T}(\mathbf{x}_{i,t} - \bar{\bar{\mathbf{x}}})(y_{i,t} - \bar{\bar{y}}))\\
  &\text{where}　\bar{\bar{\mathbf{x}}} = \frac{1}{nT}\sum_{i=1}^{n}\sum_{i=1}^{T}\mathbf{x}_{i,t}　\text{and}　\bar{\bar{y}} = \frac{1}{nT}\sum_{i=1}^{n}\sum_{i=1}^{T}y_{i,t}
\end{align*}
ここで, $\mathbf{b}^{POLS}$は$\beta$の最良一致推定量である.\\

\subsubsection{変量効果モデル}
$\mathbf{z}_i$は$\mathbf{x}_{i,t}$と無相関と仮定したモデル. $\mathbf{E}[\mathbf{z}_{i}|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}] = \mathbf{E}[\mathbf{z}_{i}] = \mu_{\mathbf{z}}$と仮定する. ${u}_i = \mathbf{z}_{i}^T \alpha - \mu_{\mathbf{z}}^T \alpha = \mathbf{z}_{i}^T \alpha - \alpha_1$と表記すると, 以下のように変形可能. 
\begin{equation*}
  y_{i,t} = \mathbf{x}_{i,t}^T \beta + \mathbf{z}_{i}^T \alpha + \epsilon_{i,t} = \alpha_1 + \mathbf{x}_{i,t}^T \beta + {u}_i + \epsilon_{i,t} = \alpha_1 + \mathbf{x}_{i,t}^T \beta + \eta_{i,t}
\end{equation*}
$\eta_{i,t} = {u}_i + \epsilon_{i,t}$. 更に以下を仮定する.
\begin{align*}
  &\mathbf{(RE1)}　\mathbb{E}[\epsilon_{i,t}|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}]=0\\
  &\mathbf{(RE2)}　(\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}, \epsilon_{i,1}, \dots, \epsilon_{i,T}) \forall i\text{はそれらの同時分布からi.i.d.抽出される}\\
  &\mathbf{(RE3)}　(\mathbf{x}_{i,t}, \epsilon_{i,t})\text{は無限ではない4次のモーメントを持つ}\\
  &\mathbf{(RE4)}　\text{完全な多重共線性が存在しない}\\
  &\mathbf{(RE5)}　Var(\epsilon_{i,t}|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}) = \sigma_\epsilon^2,　Cov(\epsilon_{i,t}\epsilon_{i,s}|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}) = 0　\text{for}　t \neq s\\
  &\mathbf{(RE6)}　{Var}({u}_{i}|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}) = \sigma_u^2,　Cov(\epsilon_{i,t}{u}_{i}|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}) = 0
\end{align*}
モデルには欠落変数が無いが, 系列相関の問題は存在する. 
\begin{equation*}
  \Sigma = \mathbf{E}[\eta_i\eta_i^T|\mathbf{x}_{i,1}, \mathbf{x}_{i,2}, \dots, \mathbf{x}_{i,T}]
  =
  \begin{pmatrix}
    \sigma_\epsilon^2 + \sigma_u^2 & \sigma_u^2 & \sigma_u^2 &\dots&\sigma_u^2\\
    \sigma_u^2 &\sigma_\epsilon^2 + \sigma_u^2 & \sigma_u^2 &\dots&\sigma_u^2\\
    \\
    &&&\ddots&\\
    \sigma_u^2&\sigma_u^2&\sigma_u^2&\dots&\sigma_\epsilon^2 + \sigma_u^2
  \end{pmatrix}
\end{equation*}
最早POLSは効率性を持たないため, 代わりにGLS推定量$\mathbf{b}^{GLS}$を用いて$\beta$を推定する. データを適切に変形して, 以下を得る.
\begin{equation*}
  y_{i,t} - \theta\bar{y}_{i}= \alpha(1-\theta) + (\mathbf{x}_{i,t} - \theta\bar{\mathbf{x}}_{i})^T \beta + (\eta_{i,t} - \theta\bar{\eta}_{i})　\mathbf{with}　\theta = 1 - \sqrt{\frac{\sigma_\epsilon^2}{\sigma_\epsilon^2 + T \sigma_u^2}}
\end{equation*}
この回帰によって得られるGLS推定量を変量効果推定量(Random Effects Estimator, RE Estimator)と呼ぶ. 特に, $\sigma_u^2 = 0$で観測不能な異質性が存在しない時, $\theta = 0$であり, $\mathbf{b}^{GLS} = \mathbf{b}^{POLS}$で両推定量が一致する. プール回帰との検定は, 帰無仮説$\sigma_z^2=0$のラグランジュ乗数検定で行う. また, $T \to \infty$または$\sigma_u^2 \gg \sigma_\epsilon^2$ならば, $\theta = 1$であり, このGLSが偏差同士を回帰していることとなるので$\mathbf{b}^{GLS} = \mathbf{b}^{FE}$となる(FE推定量は後述, 既出のそれの一般化).\\

\subsubsection{固定効果モデル}
$\mathbf{z}_i$は$\mathbf{x}_{i,t}$と相関する. 
\begin{equation*}
  y_{i,t} = \mathbf{x}_{i,t}^T \beta + \mathbf{z}_{i}^T \alpha + \epsilon_{i,t} = \mathbf{x}_{i,t}^T \beta + c_i + \epsilon_{i,t}
\end{equation*}
仮定は単回帰で導入したものと同様. FE推定量は以下のように与えられる.
\begin{equation*}
  \mathbf{b}^{FE} = (\sum_{i=1}^{n}\sum_{i=1}^{T}(\mathbf{x}_{i,t} - \bar{\mathbf{x}}_i)(\mathbf{x}_{i,t} - \bar{\mathbf{x}}_i)^T)^{-1} (\sum_{i=1}^{n}\sum_{i=1}^{T}(\mathbf{x}_{i,t} - \bar{\mathbf{x}}_i)(y_{i,t} - \bar{y}_i))
\end{equation*}
FE推定量は$n$個のダミーを追加したモデルと同じ推定量をだすことから, 最小二乗ダミー推定量とも呼ぶ. プール回帰とFEは通常の$F$検定の枠組みで$F(n - 1, nT - n - K)$で区別可能である. \\

\subsubsection{FE, REの決定, ハウスマン検定}
帰無仮説では, $\mathbf{z}_i$は$\mathbf{x}_{i,t}$と無相関と仮定する. つまり, 帰無仮説では変量効果と固定効果の\rmfamily\mcfamily\bfseries{両方の推定値が一致性を持つ}\mdseries . 対立仮説では, $\mathbf{z}_i$は$\mathbf{x}_{i,t}$と相関しているため, 変量効果は一致性を失うが, 固定効果は一致性を持つ. 検定統計量は$2$推定量の差に基づき, 差が大きい場合帰無仮説は棄却されます. この, いわゆるハウスマン検定統計量は, 次のように与えられる.
\begin{equation*}
  W = (\mathbf{b}^{FE} - \mathbf{b}^{GLS})^T(\hat{Var}(\mathbf{b}^{FE}) - \hat{Var}(\mathbf{b}^{GLS}))^{-1} (\mathbf{b}^{FE} - \mathbf{b}^{GLS}) \sim \chi^2(K)
\end{equation*}

\subsubsection{FE, REの決定, CREモデル}
再度$K = 1$のケース$y_{i,t} = \beta_1 {x}_{i,t,1} + c_i + \epsilon_{i,t}$について考える. 更に, $c_i = \delta_0 + \delta_1 \bar{{x}}_{i,1} + r_i$ with $Cov(\bar{{x}}_{i,1}, r_i) = 0$と特定化して以下を得る.
\begin{equation*}
  y_{i,t} = \delta_0 + \beta_1 {x}_{i,t,1} + \delta_1 \bar{{x}}_{i,1} + r_i + \epsilon_{i,t}
\end{equation*}
上のモデルは, 相関変量効果モデル(Correlated Random Effects, CRE model)と呼ばれ, RE推定法によって推定が可能である. $b_1^{CRE} = b_1^{FE}$であることも示される. 帰無仮説$\delta_1 = 0$を検定することでRE, FEどちらが適当かを決定する事が出来る. さらに, \rmfamily\mcfamily\bfseries{クラスター標準誤差}\mdseries を用いることによって, \rmfamily\mcfamily\bfseries{ハウスマン検定では対応できない(本当???)}\mdseries , 系列相関や不均一分散の問題にも対応することが出来る. 固定効果モデルにもクラスター標準誤差を用いるのが適切, らしい? モデルには観測可能($c_i$は観測不能な異質性を含んでいた)で時間不変の変数も追加可能である. 政策分析の場合, REは一般的に説得力に欠ける. これは, モデルに入れ込む説明変数が$c_i$の時間一定要因と相関していることが望まれるからである. ただしコントロールが適切であれば, 時間一定の変数を追加すると$c_i$からより多くの情報が取り出されるため, REは説得力を持つ可能性がある. 一致性がある場合, REは通常FEよりも効率的.

\end{document}